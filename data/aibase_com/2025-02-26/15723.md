# 阿里全面开源文生视频模型万相2.1：14B和1.3B双版本上线

**发布日期**: 2025年2月26号 9:45

![新闻图片](https://upload.chinaz.com/2025/0226/6387615991020646795175422.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/15723)

## 内容

今日，阿里巴巴官方宣布全面开源旗下视频生成模型万相2.1模型，14B和1.3B双版本上线。其中，专业版14B，高性能，提供业界顶尖的表现力可满足对视频质量有极高要求的场景;而极速版1.3B，适合消费级显卡，8.2GB显存即可生成480P高质量视频，适用于二次模型开发和学术研究。据官方介绍，本次开源的 Wan2.1在处理复杂运动、还原真实物理规律、提升影视质感及优化指令遵循方面展现出显著优势，能够满足创作者、开发者和企业用户的多样化需求。借助于通义万相，用户可以轻松实现高质量的视频生成，尤其在广告和短视频领域，满足了对创意的高要求。在权威评测集 VBench 中，通义万相以总分86.22% 高居榜首，远超 Sora、Minimax、Luma 等国内外其他视频生成模型。该评测基于主流的 DiT 和线性噪声轨迹 Flow Matching 范式，通过一系列技术创新提升了模型的生成能力。特别是自研的高效3D 因果 VAE 模块，成功实现256倍无损视频隐空间压缩，支持任意长度视频的高效编码与解码。通义万相在生成视频的过程中，采用了基于主流 DiT 结构的 Full Attention 机制，有效建模时空依赖性，确保生成视频的高质量与一致性。模型的训练策略采用6阶段分步训练法，从初步的低分辨率数据训练逐步引入高分辨率数据，以保证模型在不同条件下的优异表现。此外，通义万相在数据处理方面也采取了严格的清洗流程，以确保训练数据的高质量。在训练与推理效率优化方面，通义万相采用了多种先进技术，如分布式训练策略、激活值优化和显存管理，确保模型训练的稳定性与推理效率。通过与阿里云训练集群的智能调度结合，模型在训练过程中能够自动识别故障并快速重启，确保训练过程的顺利进行。通义万相2.1已在 GitHub、Hugging Face 等平台开源，支持多种主流框架，为开发者和研究者提供了便利的使用体验。无论是快速原型开发还是高效生产部署，通义万相都能满足不同用户的需求，为视频生成技术的发展注入了新的活力。魔塔社区入口:https://modelscope.cn/organization/Wan-AI划重点:🌟 通义万相2.1开源，支持多样化视频生成需求。🏆 在 VBench 评测中以86.22% 高分获胜，领先其他模型。🚀 采用分步训练及多项技术优化，提升了生成效率和质量。
