# DeepSeek开源周第3天：发布DeepGEMM，FP8 GEMM库助力AI训练与推理

**发布日期**: 2025年2月26号 9:33

![新闻图片](https://pic.chinaz.com/picmap/thumb/202502051542244255_2.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/15722)

## 内容

中国人工智能公司DeepSeek在其“开源周”第3天宣布推出DeepGEMM——一款支持FP8通用矩阵乘法（GEMM）的开源库。这一工具专为密集型和混合专家(MoE)矩阵运算设计，为DeepSeek V3和R1模型的训练与推理提供强大支持。官方消息通过X平台发布，迅速引发技术社区的热烈反响。据DeepSeek官方账号发布的帖子，DeepGEMM在NVIDIA Hopper GPU上可实现高达1350+ TFLOPS的FP8计算性能。其核心逻辑仅约300行代码，却能在大多数矩阵尺寸上超越专家调优的内核，展现了极高的效率和简洁性。该库无需复杂依赖，采用即时编译（Just-In-Time）技术，支持密集布局和两种MoE布局，设计上“像教程一样干净”，便于开发者学习和使用。X用户@TechBitDaily评论称:“DeepGEMM的发布是DeepSeek开源周的一大亮点，其FP8性能和简洁设计令人印象深刻。”另一位用户@AIObserverCN指出，该库在支持MoE模型的高效训练方面具有显著优势，可能推动AI社区在Hopper架构上的进一步创新。作为开源周的一部分，DeepGEMM的发布延续了DeepSeek推动AI技术透明化和社区协作的承诺。此前，该公司已在首两天发布了FlashMLA和DeepEP工具，分别聚焦于快速语言模型架构和专家并行通信。此次DeepGEMM的亮相，进一步展示了其在AI基础设施建设上的技术实力。业内人士认为，这款库不仅将提升DeepSeek自家模型的性能，也为全球开发者提供了一个高效、易用的矩阵运算工具，未来应用前景可期。用户现可通过GitHub获取DeepGEMM，探索其在AI训练与推理中的潜力。项目地址：https://github.com/deepseek-ai/DeepGEMM
