# ​腾讯AI实验室与上海交大携手破解o1模型 “过度思考” 难题

**发布日期**: 2025年1月2号 9:02

![新闻图片](https://upload.chinaz.com/2025/0102/6387140530290351798902763.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14401)

## 内容

近年来，随着大语言模型（LLM）的广泛应用，这些模型在复杂推理和问题解决任务中发挥了重要作用。其中，受 OpenAI 的 o1架构启发的 o1-like 模型以其独特的人类思维、逐步推理的能力脱颖而出。然而，这些模型也存在一个显著的低效问题，即 “过度思考”。所谓过度思考，是指模型在处理一些简单问题时，往往会消耗不必要的计算资源，甚至在推理过程中重复无谓的步骤。例如，在解决 “2+3” 这样简单的算术题时，o1-like 模型可能会生成过于详细的推理，使用的 token 数量远超传统的 LLM，这不仅增加了计算成本，也限制了它们在资源受限场景下的实际应用。针对这一问题，腾讯 AI 实验室和上海交通大学共同发布了一项新研究，深入探讨 o1-like 模型中的过度思考现象，并集中优化测试时的计算资源。研究通过在 GSM8K、MATH500和 AIME 等数据集上进行实验，揭示了这些模型在面对简单问题时倾向于生成冗余解答的特征。为此，研究人员引入了两个评估指标 —— 结果效率和过程效率，以全面评估模型在推理时的资源利用情况，这两个指标分别考量答案的正确性和中间推理步骤的相关性。为了解决过度思考问题，研究者提出了一种自我训练的方法，将效率指标直接整合到模型训练过程中。这一方法强调了早期准确响应的重要性，从而减少冗余推理，同时保留了模型的反思能力。研究中，第一正确解（FCS）和 FCS + 反思策略成为核心方法。以 QwQ-32B-Preview 模型为例，在 MATH500数据集上的 token 使用量减少了48.6%。除了计算节省外，这些方法还提高了推理的可解释性，并使其能够在计算资源有限的场景中部署。实验结果显示，这些以效率为中心的策略显著降低了 token 使用量，同时保持或提高了简单任务的准确性。例如，在 MATH500数据集中，FCS + 反思策略使结果效率从52.3% 提升至75.8%。更高的过程效率也表明推理步骤中的冗余性减少。在更具挑战性的数据集如 GPQA 和 AIME 中，优化后的模型依然保持了强大的性能，同时减少了计算需求。研究结果表明，针对性训练策略能够有效解决低效问题，同时在多种任务中保留模型的能力。腾讯 AI 实验室与上海交通大学的这项研究强调了 o1-like 模型中的过度思考问题，并提出了高效利用资源的切实解决方案。这些新指标和训练方法的提出，对于提升先进推理模型的可扩展性和应用性具有重要意义。在人工智能系统不断演进的过程中，确保计算资源的高效使用将成为一个关键关注点，从而使这些技术能够得到更广泛的应用和可持续的使用。项目入口:https://arxiv.org/abs/2412.21187划重点:🔍 研究揭示 o1-like 模型在简单问题上存在 “过度思考” 现象，导致不必要的计算资源浪费。⚙️ 通过引入结果效率和过程效率指标，研究者优化模型的计算资源利用，提升推理的有效性。📉 实验结果显示优化策略显著减少 token 使用，同时保持或提高模型在简单任务上的准确性。
