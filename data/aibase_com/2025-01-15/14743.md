# 新型AI模型Transformer²：像章鱼一样灵活，动态调整权重，自我适应环境

**发布日期**: 2025年1月15号 15:40

![新闻图片](https://pic.chinaz.com/picmap/thumb/202405161743122232_2.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14743)

## 内容

传统的大型语言模型（LLM）微调方法通常计算密集，且在处理多样化任务时显得静态。为了解决这些挑战，Sakana AI 推出了一种名为 Transformer² 的新型自适应框架。Transformer² 能够在推理过程中实时调整LLM的权重，使其能够适应各种未知的任务，就像章鱼一样灵活。Transformer² 的核心在于一个两阶段机制:第一阶段，一个调度系统会分析用户的查询，识别任务的属性。第二阶段，系统会动态混合多个“专家”向量。这些向量是使用强化学习训练出来的，每个向量都专注于特定类型的任务，从而针对当前任务生成定制化的模型行为。这种方法与传统的微调方法（如LoRA）相比，使用更少的参数，效率更高。Transformer² 在不同的LLM架构和模态(包括视觉语言任务)中都展现出了强大的适应性。Transformer² 的关键技术奇异值微调（SVF）:这是一种新颖的参数高效微调方法，它通过提取和调整模型权重矩阵中的奇异值来实现。这种方法降低了过拟合的风险，减少了计算需求，并允许固有的组合性。通过在狭窄的数据集上使用强化学习训练，可以获得一组有效的特定领域“专家”向量，从而直接优化各个主题的任务表现。自适应策略:在推理阶段，Transformer² 采用三种不同的自适应策略来组合SVF训练的专家向量。这些策略可以根据测试时的条件，动态调整LLM的权重，从而实现自我适应。Transformer² 的优势动态适应性:Transformer² 能够根据操作环境或内部状态的变化来评估和修改自身的行为，无需外部干预。参数高效:与LoRA等方法相比，SVF 使用的参数更少，但性能更高。模块化能力:专家向量提供了模块化的能力，而自适应策略则可以动态确定并组合最合适的向量来处理输入任务。强化学习优化:通过强化学习，可以直接优化任务表现，而无需依赖昂贵的微调程序和大型数据集。跨模型兼容性:SVF 专家向量可以在不同的LLM模型之间进行迁移，这得益于其固有的排序结构。实验结果在多个LLM和任务上进行的实验表明，SVF 的性能始终优于传统的微调策略（如LoRA）。Transformer² 的自适应策略在各种未知的任务中都表现出了显著的改进。使用分类专家进行任务分类比直接使用提示工程的分类精度更高。在不同的模型和任务组合中，自适应系数（αk）的贡献是不均匀的。未来展望Transformer² 虽然取得了显著的进展，但仍有进一步改进的空间。未来的研究可以探索模型合并技术，将不同的专业模型合并为一个更强大的模型。此外，还可以研究如何扩展CEM方法，以应对更多的专业领域。总而言之，Transformer² 代表了自适应LLM领域的一大飞跃，为构建真正动态、自我组织的AI系统铺平了道路。论文地址：https://arxiv.org/pdf/2501.06252
