# 全新 VideoRAG 框架： 利用视频内容提升查询响应的准确性

**发布日期**: 2025年1月15号 10:39

![新闻图片](https://pic.chinaz.com/picmap/thumb/202304231721019071_2.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14724)

## 内容

随着视频技术的快速发展，视频已成为信息检索和理解复杂概念的重要工具。视频结合了视觉、时间和上下文数据，提供了超越静态图像和文本的多模态表现。如今，随着视频分享平台的普及和大量教育及信息视频的涌现，利用视频作为知识源为解决需要详细背景、空间理解和过程演示的查询提供了前所未有的机会。然而，现有的检索增强生成（RAG）系统往往忽视了视频数据的全部潜力。这些系统通常依赖文本信息，偶尔使用静态图像来支持查询响应，却未能捕捉视频所包含的视觉动态和多模态线索，这对于复杂任务至关重要。传统方法要么在没有检索的情况下预定义查询相关视频，要么将视频转化为文本格式，从而失去重要的视觉上下文和时间动态，限制了提供准确和信息丰富的答案的能力。为了解决这些问题，来自韩国科学技术院（KaIST）和 DeepAuto.ai 的研究团队提出了一种新颖的框架 ——VideoRAG。该框架能够动态检索与查询相关的视频，并将视觉和文本信息整合到生成过程中。VideoRAG 利用先进的大型视频语言模型(LVLMs)实现多模态数据的无缝集成，确保检索到的视频与用户查询的上下文一致，并保持视频内容的时间丰富性。VideoRAG 的工作流程分为两个主要阶段:检索和生成。在检索阶段，框架通过查询识别与其视觉和文本特征相似的视频。在生成阶段，利用自动语音识别技术为没有字幕的视频生成辅助文本数据，从而确保所有视频的响应生成都能有效贡献信息。相关的检索视频进一步输入生成模块，整合视频帧、字幕和查询文本等多模态数据，借助 LVLMs 处理，从而生成长篇且丰富、准确、上下文恰当的响应。VideoRAG 在 WikiHowQA 和 HowTo100M 等数据集上进行了广泛实验，结果显示其响应质量明显优于传统方法。这一新框架不仅提升了检索增强生成系统的能力，也为未来的多模态检索系统设定了新的标准。论文：https://arxiv.org/abs/2501.05874划重点:📹 ** 新框架 **:VideoRAG 动态检索相关视频，将视觉和文本信息融合以提升生成效果。🔍 ** 实验验证 **:在多个数据集上测试，显示出明显优于传统 RAG 方法的响应质量。🌟 ** 技术革新 **:利用大型视频语言模型，VideoRAG 开启了多模态数据整合的新篇章。
