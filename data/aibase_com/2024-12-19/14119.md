# 重磅突破！新型文本驱动风格转换技术大幅提升图像生成质量

**发布日期**: 2024年12月19号 7:47

![新闻图片](https://pic.chinaz.com/thumb/2024/1219/24121903470140097783.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14119)

## 内容

文本驱动的风格转换是图像合成领域的一项重要任务，旨在将参考图像的风格与文本提示所描述的内容相融合。 近期，文本到图像生成模型取得了显著进展，能够实现更精细的风格转换，同时保持内容的高保真度。这项技术在数字绘画、广告和游戏设计等领域具有巨大的实用价值。然而，现有的风格转换技术仍存在一些不足之处，主要挑战包括:风格过拟合:现有模型倾向于复制参考图像的所有元素，导致生成图像过于贴近参考风格图像的特征，限制了生成图像的审美灵活性和适应性。文本对齐不准确:模型可能优先考虑参考图像的主导颜色或图案，即使这些元素与文本提示中的指令相矛盾。生成伪影:风格转换可能引入不必要的伪影，例如重复出现的图案（如棋盘格效应），破坏了图像的整体布局。为了解决这些问题，研究人员提出了三种互补策略:基于AdaIN的跨模态融合:利用**自适应实例规范化（AdaIN）**机制，将风格图像特征融入文本特征中，然后再将其与图像特征融合。这种自适应融合创建了一个更具凝聚力的引导特征，使风格特征与基于文本的指令更加和谐地对齐。AdaIN通过调整内容特征以反映风格统计信息，有效地将风格融入内容，同时保留内容与文本描述的一致性。基于风格的无分类器引导（SCFG）:开发一种风格引导方法，专注于目标风格并减少不必要的风格特征。 通过使用布局控制的生成模型(例如 ControlNet)，生成一个缺乏目标风格的“负”图像。此负图像的作用类似于扩散模型中的“空”提示，使得引导可以完全专注于目标风格元素。使用教师模型进行布局稳定:在生成的早期阶段引入教师模型。该教师模型基于原始的文本到图像模型，与风格模型同时执行带有相同文本提示的去噪生成，并在每个时间步共享其空间注意力图。 此方法确保了稳定和一致的空间分布，有效地减轻了棋盘格伪影等问题。此外，它还实现了同一文本提示在不同风格参考图像之间保持一致的空间布局。研究人员通过大量实验验证了这些方法的有效性。结果表明，该方法能够显著提高生成图像的风格转换质量，并与文本提示保持一致性。更重要的是，该方法可以集成到现有的风格转换框架中，无需进行微调。研究人员通过实验发现，交叉注意力机制中的不稳定会导致伪影的出现。自注意力机制在保持图像的布局和空间结构方面起着关键作用，该机制通过捕获高级空间关系来稳定生成过程中的基本布局。通过选择性地替换风格化图像中的某些自注意力图，可以保留图像中关键特征的空间关系，确保核心布局在整个去噪过程中保持一致.此外，基于风格的无分类器引导（SCFG） 有效地解决了风格歧义的问题，它可以选择性地强调所需的风格元素，同时过滤掉不相关的或冲突的特征。该方法通过使用布局控制模型生成负风格图像，使模型可以专注于传输所需的风格组件，从而缓解了过度拟合不相关风格组件的风险。研究人员还进行了消融实验，以评估每个组件的影响。结果表明，基于AdaIN的跨模态融合和教师模型都能显著提高文本对齐的准确性，并且它们具有互补效应。总而言之，这项研究提出的方法能够有效缓解现有文本驱动风格转换技术中存在的风格过拟合和布局不稳定性问题，从而实现更高质量的图像生成，并为文本到图像的合成任务提供了一个多功能且强大的解决方案。论文地址：https://arxiv.org/pdf/2412.08503
