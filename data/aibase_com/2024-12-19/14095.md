# 超越Gemma2！​IBM发布Granite3.1模型：支持128K上下文长度

**发布日期**: 2024年12月19号 1:49

![新闻图片](https://upload.chinaz.com/2024/1219/6387019850574666674660292.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14095)

## 内容

IBM 正式发布了其新一代开源大语言模型 Granite3.1，力图在企业级 AI 领域占据领先地位。这一系列模型具备128K 的扩展上下文长度、嵌入模型、内置的幻觉检测功能以及性能的显著提升。IBM 声称，Granite8B Instruct 模型在相同规模的开源竞争对手中表现最佳，包括 Meta 的 Llama3.1、Qwen2.5和谷歌的 Gemma2。Granite3.1模型的发布是在 IBM 快速迭代 Granite 系列的背景下进行的，早在10月份就推出了 Granite3.0。IBM 透露，其与生成 AI 相关的业务收入已达到20亿美元。新版本的核心理念是将更多功能集成到更小的模型中，以便企业用户能够更轻松地运行和更具成本效益。IBM 研究部副总裁大卫・考克斯（David Cox）表示，Granite 模型广泛应用于 IBM 内部产品、咨询服务以及客户服务，同时也以开源形式发布，因此需要在各个方面都达到高水平。模型的性能评估不仅仅依赖于速度，还包括效率，帮助用户在获取结果时节省时间。在上下文长度方面，Granite3.1的提升尤为明显，从初版的4K 扩展至128K，这对企业 AI 用户尤为重要，尤其是在检索增强生成（RAG）和智能代理 AI 方面。延长的上下文长度允许模型处理更长的文档、日志和对话，使其更好地理解和响应复杂查询。IBM 还推出了一系列嵌入模型，以加快数据转换为向量的过程。其中 Granite-Embedding-30M-English 模型的查询时间为0.16秒，速度优于竞争对手的产品。为了实现 Granite3.1的性能提升，IBM 在多阶段训练流程和高质量训练数据的使用上进行了创新。在幻觉检测方面，Granite3.1模型将幻觉保护集成到了模型内部，能够自我检测并减少错误输出。这种内置检测功能优化了整体效率，减少了推理调用次数。当前，Granite3.1模型已向企业用户免费开放，并通过 IBM 的 Watsonx 企业 AI 服务提供。未来，IBM 计划保持快速更新的节奏，Granite3.2将于2025年初推出多模态功能。官方博客:https://www.ibm.com/new/announcements/ibm-granite-3-1-powerful-performance-long-context-and-more划重点:🌟 IBM 推出 Granite3.1模型，旨在开源大语言模型市场占据领先地位。💡 新模型支持128K 上下文长度，显著提升了处理能力与效率。🚀 幻觉检测功能被集成到模型中，优化了整体性能和准确性。
