# 谷歌Gemini正在迫使外包人员评估专业领域外的 AI 响应

**发布日期**: 2024年12月19号 1:21

![新闻图片](https://pic.chinaz.com/picmap/202312070835429226_0.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14088)

## 内容

近日，谷歌旗下的 AI 项目 Gemini 因其内部新规引发了对信息准确性的担忧。据报道，负责评估 AI 生成内容的外包人员被要求对他们不具备专业知识的领域进行评分，尤其是在医疗健康等敏感话题上。这些外包人员来自于全球技术服务公司 GlobalLogic，谷歌要求他们评估 AI 生成的回复，主要考量 “真实性” 等因素。此前，外包人员可以选择跳过那些他们没有相关专业知识的问题，例如，他们可以在遇到关于心脏病学的专业问题时，选择不作评估。这样做是为了确保评分的准确性，只有具备相关背景的人员才能进行有效评估。然而，上周 GlobalLogic 宣布了谷歌的最新要求，外包人员现在不再被允许跳过这类专业领域的问题，而是被要求对他们理解的部分进行评分，并说明他们缺乏相关领域的知识。这一变化引发了外包人员的广泛担忧，他们认为这种做法可能会影响 Gemini 在某些复杂话题上的准确性。例如，一些外包人员在内部通讯中提到，之前的跳过选项是为了提高评分的准确性，然而新规的实施却使得他们不得不评估一些自己毫无经验的问题，如罕见疾病等。内部邮件显示，原本的规定是:“如果你对这个任务没有必要的专业知识，请跳过。” 而新规定则是:“不应跳过需要专业知识的提示。” 这一政策的转变，让外包人员感到不安。在新规下，外包人员只能在两种情况下跳过评估任务:一种是完全缺失信息，例如缺少完整的提示或回复;另一种是内容可能有害，需要特殊同意才能进行评估。虽然这些新规旨在提升 Gemini 的性能，但却可能在实际操作中影响其对复杂话题的理解与反馈。谷歌方面对此事并未做出回应，而外包人员的担忧也在逐渐发酵。划重点:🔍 外包人员被要求评估他们不具备专业知识的 AI 生成回复，尤其是医疗等敏感领域。🚫 新规取消了 “跳过” 选项，要求外包人员在缺乏专业知识的情况下仍需评分。📉 这一政策可能影响 Gemini 在复杂话题上的准确性，引发外包人员的不安与担忧。
