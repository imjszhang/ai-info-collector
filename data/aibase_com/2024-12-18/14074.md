# 电磁信号窃取：AI 模型盗窃背后的隐秘危机！

**发布日期**: 2024年12月18号 7:02

![新闻图片](https://pic.chinaz.com/picmap/201811151621141028_13.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14074)

## 内容

近期，北卡罗来纳州立大学的研究人员提出了一种新方法，通过捕获计算机发出的电磁信号来提取人工智能（AI）模型，准确率高达99% 以上。这一发现可能对商业 AI 发展构成挑战，尤其是在 OpenAI、Anthropic 和谷歌等公司已经大量投资于专有模型的背景下。不过，专家们指出，这种技术在现实世界中的实际影响以及防御措施仍不明确。CUDO Compute 的首席营销官拉斯・奈曼（Lars Nyman）表示，AI 盗窃不仅仅是模型本身的损失，还可能引发一系列连锁反应，如竞争对手利用多年的研发成果、监管机构调查知识产权的管理失当，甚至客户因发现自身的 AI “独特性” 并不独特而提起诉讼。这种情况可能促使行业内推动标准化审计，就像 SOC2或 ISO 认证一样，以此区分安全的企业与不负责任的企业。近年来，针对 AI 模型的黑客攻击威胁日益严重。商业界对 AI 的依赖使得这一问题更加突出。最近的报告显示，数千个恶意文件被上传至 Hugging Face，这一 AI 工具的关键存储库，严重危害了零售、物流和金融等行业使用的模型。国家安全专家警告说，薄弱的安全措施可能导致专有系统面临盗窃风险，正如 OpenAI 的安全漏洞所示。被盗的 AI 模型可能被逆向工程或出售，这将削弱企业的投资，并破坏信任，允许竞争对手迅速赶超。北卡罗来纳州立大学的研究团队通过在谷歌边缘张量处理单元（TPU）附近放置探头，分析其信号，从而揭示了模型结构的关键信息。该攻击方式并不需要直接访问系统，这使得 AI 知识产权面临严重安全风险。研究合著者、电子与计算机工程副教授艾丁・艾苏(Aydin Aysu)强调，构建一个 AI 模型不仅费用高昂且需要大量计算资源，因此防止模型被盗取是至关重要的。随着 AI 技术的应用日益广泛，企业需要重新审视某些用于 AI 处理的设备。技术顾问苏里尔・阿雷拉诺（Suriel Arellano）认为，企业可能会转向更集中和安全的计算，或者考虑其他更不易被盗的替代技术。尽管盗窃的风险存在，AI 也在加强网络安全，通过自动化威胁检测和数据分析提升响应效率，助力识别潜在威胁并学习应对新攻击。划重点:🔍 研究人员展示了通过捕获电磁信号提取 AI 模型的方法，准确率超过99%。💼 AI 模型盗窃可能导致竞争对手利用企业多年研发成果，影响商业安全。🔒 企业需加强 AI 模型的安全防护，以应对不断增加的黑客攻击威胁。
