# 通义千问开源Qwen2.5-Coder全系列 代码能力追平 GPT-4o

**发布日期**: 2024年11月12号 8:38

![新闻图片](https://upload.chinaz.com/2024/1112/6386699747131805834467754.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/13143)

## 内容

通义千问团队近日宣布开源其最新的Qwen2.5-Coder全系列，这一举措旨在推动Open Code LLMs的发展。Qwen2.5-Coder以其强大、多样和实用性受到关注。Qwen2.5-Coder-32B-Instruct模型在代码能力上达到了SOTA水平，与GPT-4o相当，展现出全面的能力，包括代码生成、代码修复和代码推理。它在多个代码生成基准测试中取得了最佳表现，并在Aider基准测试中达到73.7分，与GPT-4o表现相当。Qwen2.5-Coder支持超过40种编程语言，并在McEval上获得65.9分，其中Haskell、Racket等语言的表现尤为突出。这得益于其预训练阶段独特的数据清洗和配比。此外，Qwen2.5-Coder-32B-Instruct在多编程语言的代码修复能力上也表现出色，在MdEval基准测试中得分75.2，排名第一。为了检验Qwen2.5-Coder-32B-Instruct在人类偏好上的对齐表现，构建了一个内部标注的代码偏好评估基准Code Arena。结果显示Qwen2.5-Coder-32B-Instruct在偏好对齐方面具有优势。Qwen2.5-Coder系列此次开源了四个尺寸的模型，包括0.5B/3B/14B/32B，覆盖了主流的六个模型尺寸，满足不同开发者的需求。官方提供了Base和Instruct两种模型，前者作为开发者微调模型的基础，后者作为官方对齐的聊天模型。模型尺寸与效果之间存在正相关，Qwen2.5-Coder在所有尺寸下都取得了SOTA表现。Qwen2.5-Coder的0.5B/1.5B/7B/14B/32B模型采用Apache2.0许可，而3B模型为Research Only许可。团队通过评估不同尺寸的Qwen2.5-Coder在所有数据集上的表现，验证了Scaling在Code LLMs上的有效性。Qwen2.5-Coder的开源，为开发者提供了一个强大、多样化且实用的编程模型选择，有助于推动编程语言模型的发展和应用。Qwen2.5-Coder模型链接:https://modelscope.cn/collections/Qwen25-Coder-9d375446e8f5814a
