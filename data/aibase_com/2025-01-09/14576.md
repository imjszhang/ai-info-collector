# 微软正式开源超强小模型Phi-4 性能测试超越GPT-4o、Llama-3.1

**发布日期**: 2025年1月9号 9:48

![新闻图片](https://upload.chinaz.com/2025/0109/6387201282620984153280147.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14576)

## 内容

微软近期在 Hugging Face 平台上发布了名为 Phi-4的小型语言模型，这款模型的参数量仅为140亿，但在多项性能测试中表现出色，超越了众多知名模型，包括 OpenAI 的 GPT-4o 及其他同类开源模型如 Qwen2.5和 Llama-3.1。在之前的在美国数学竞赛 AMC 的测试中，Phi-4获得了91.8分，显著优于 Gemini Pro1.5、Claude3.5Sonnet 等竞争对手。更令人惊讶的是，这款小参数模型在 MMLU 测试中取得了84.8的高分，充分展现了其强大的推理能力和数学处理能力。与许多依赖于有机数据源的模型不同，Phi-4采用了创新的方法来生成高质量的合成数据，包括多智能体提示、指令反转和自我修正等技术。这些方法大大增强了 Phi-4在推理和解决问题方面的能力，使其能够处理更为复杂的任务。Phi-4采用了仅解码器的 Transformer 架构，支持长达16k 的上下文长度，非常适合处理大输入的数据。其预训练过程中使用了约10万亿个 token，结合合成数据与经过严格筛选的有机数据，确保在 MMLU 和 HumanEval 等基准测试中表现出色。Phi-4的特点和优势包括:适用于消费级硬件的紧凑性和高效性;在 STEM 相关任务中超越了前代和更大模型的推理能力;支持与多样化的合成数据集进行微调，便于满足特定领域的需求。此外，Phi-4在 Hugging Face 平台上提供了详细的文档和 API，方便开发者进行集成。在技术创新方面，Phi-4的开发主要依托三个支柱:生成合成数据的多智能体和自我修正技术，后期训练增强方法如拒绝采样和直接偏好优化（DPO），以及严格过滤的训练数据，确保与基准的重叠数据最小化，提高了模型的泛化能力。此外，Phi-4利用关键标记搜索(PTS)来识别决策过程中的重要节点，从而优化其处理复杂推理任务的能力。随着 Phi-4的开源，开发者们的期待终于成真。该模型不仅可以在 HuggingFace 平台下载，还支持在 MIT 许可证下进行商业用途。这一开放政策吸引了大量开发者和 AI 爱好者的关注，HuggingFace 的官方社交媒体也对此表示祝贺，称其为 “史上最好的14B 模型”。模型入口:https://huggingface.co/microsoft/phi-4划重点:🧠 ** 微软推出小参数模型 Phi-4，参数仅140亿却超越多款知名模型。**📊 ** 在多项性能测试中，Phi-4表现优异，特别是在数学与推理方面。**🌐 Phi-4现已开源，并支持商业用途，吸引了众多开发者的关注与使用。
