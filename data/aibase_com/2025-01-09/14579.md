# 字节联合高校出品！STAR 模型：提升视频清晰度和分辨率

**发布日期**: 2025年1月9号 10:11

![新闻图片](https://upload.chinaz.com/2025/0109/6387201424567433971690442.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14579)

## 内容

近日，南京大学的研究团队与字节跳动、西南大学联合推出了一项创新技术 ——STAR（Spatial-Temporal Augmentation with Text-to-Video Models），旨在利用文本到视频模型，实现真实世界视频的超分辨率处理。该技术结合了时空增强方法，能够有效提高低分辨率视频的质量，尤其适用于在视频分享平台上下载的低清晰度视频。为了方便研究者和开发者使用，研究团队已经在 GitHub 上发布了 STAR 模型的预训练版本，包括 I2VGen-XL 和 CogVideoX-5B 两种型号，以及相关的推理代码。这些工具的推出标志着在视频处理领域的一次重要进展。使用该模型的过程相对简单。首先，用户需要从 HuggingFace 下载预训练的 STAR 模型，并将其放入指定目录。接着，准备待测试的视频文件，并选择适合的文本提示选项，包括无提示、自动生成或手动输入提示。用户只需调整脚本中的路径设置，便可轻松进行视频超分辨率的处理。该项目特别设计了两种基于 I2VGen-XL 的模型，分别用于不同程度的视频降质处理，确保能够满足多种需求。此外，CogVideoX-5B 模型专门支持720x480的输入格式，为特定场景提供了灵活的选择。该研究不仅为视频超分辨率技术的发展提供了新的思路，还为相关领域的研究者们开辟了新的研究方向。研究团队对 I2VGen-XL、VEnhancer、CogVideoX 和 OpenVid-1M 等前沿技术表示感谢，认为这些技术为他们的项目奠定了基础。项目入口:https://github.com/NJU-PCALab/STAR划重点:🌟 新技术 STAR 结合文本到视频模型，实现视频超分辨率，提升视频质量。🛠️ 研究团队已发布预训练模型和推理代码，使用过程简单明了。📩 提供联系方式，鼓励用户与研究团队进行交流与探讨。
