# ​AI 聊天机器人在时事问题上频频出错，BBC 研究揭示事实扭曲

**发布日期**: 2025年2月11号 9:54

![新闻图片](https://pic.chinaz.com/picmap/202308011356244247_4.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/15231)

## 内容

最近，英国广播公司（BBC）的一项研究揭示，领先的人工智能助手在回答与新闻和时事相关的问题时，常常产生误导性和不准确的内容。研究表明，ChatGPT、Gemini 和 Perplexity 四种主流 AI 工具所生成的回答中，有超过一半被认为存在 “重大问题”。图源备注:图片由AI生成，图片授权服务商Midjourney研究人员要求这四款生成式 AI 工具使用 BBC 的新闻文章作为来源，回答100个相关问题。随后，这些回答由专业的 BBC 记者进行评估。结果显示，大约五分之一的答案中包含数字、日期或陈述的事实错误，而13% 的引用则是被修改过或根本不存在于所引用的文章中。例如，在涉及被定罪的新生儿护士露西・莱特比（Lucy Letby）的案件时，Gemini 的回答忽略了她被判谋杀和未遂谋杀的背景，表示 “每个人都有自己的看法来判断露西・莱特比是无辜还是有罪”。此外，微软的 C opi lot 错误地叙述了法国强奸受害者吉赛尔・佩利科(Gisèle Pelicot)的经历，而 ChatGPT 则错误地提到以色列哈马斯领导人伊斯梅尔・哈尼耶(Ismail Haniyeh)在被刺杀数月后仍在领导层中。更令人担忧的是，这项研究表明，当前这些 AI 工具在处理时事信息时存在广泛的不准确性。BBC 新闻首席执行官德博拉・特纳斯（Deborah Turness）对此发出警告，认为 “生成式 AI 工具正在玩火”，可能会削弱公众对事实的 “脆弱信任”。她呼吁 AI 公司与 BBC 合作，以生产更准确的回应，避免增加混乱和误导。这项研究还引发了对内容使用控制的问题，BBC 的生成式 AI 项目总监彼得・阿彻（Peter Archer）表示，媒体公司应当掌握其内容的使用方式，而 AI 公司应当展示其助手处理新闻的方式及产生的错误规模。他强调，这需要媒体与 AI 公司之间建立强有力的合作关系，以最大化对公众的价值。划重点:🔍 研究显示，超过一半的 AI 生成回答存在重大错误。📰 AI 助手在回答时事问题时常常产生误导性内容，影响公众信任。🤝 BBC 呼吁 AI 公司加强合作，以提高信息的准确性和可靠性。
