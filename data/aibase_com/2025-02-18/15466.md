# 到2027年，生成式 AI 将导致超 40% 的数据泄露

**发布日期**: 2025年2月18号 11:38

![新闻图片](https://pic.chinaz.com/picmap/202005261133523452_10.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/15466)

## 内容

根据 Gartner 最近的分析，到2027年，超过40% 的人工智能相关数据泄露将源于生成式人工智能（GenAI）的误用。随着 GenAI 技术的迅速普及，企业和组织在数据治理与安全措施的制定上面临着严峻挑战。尤其是在数据本地化的背景下，这一问题显得尤为突出，因为这些技术对集中计算能力的需求很高。Gartner 的副总裁分析师 Joerg Fritsch 指出，组织在集成 GenAI 工具时，常常缺乏足够的监督，导致意外的跨境数据转移。他提到，“如果员工在使用 GenAI 工具时发送了敏感提示，而这些工具和 API 又托管在未知地点，便会带来安全隐患。” 尽管这些工具可以用于经批准的商业应用，但其潜在的安全风险不容忽视。在全球范围内，缺乏一致的最佳实践和数据治理标准也是 Gartner 所指出的关键挑战。这种缺口导致市场的碎片化，迫使企业为特定地区制定策略，从而影响了它们在全球有效利用 AI 产品和服务的能力。Fritsch 还提到，“管理数据流的复杂性以及由于本地化 AI 政策带来的质量维护问题，可能会导致运营效率低下。”为了保护敏感数据和确保合规，企业需要在 AI 治理和安全方面进行投资，以应对这些风险。Gartner 预测，到2027年，全球将普遍要求 AI 治理，尤其是在主权 AI 法律和法规的框架下。未能及时整合必要治理模型的组织，将面临竞争劣势。为了降低与 AI 数据泄露相关的风险，Gartner 建议企业采取以下策略:首先，增强数据治理，包括遵守国际法规、监测意外的跨境数据转移等;其次，成立治理委员会，以提高对 AI 部署和数据处理的透明度和监督力度;最后，加强数据安全，采用先进的技术，如加密和匿名化技术，以保护敏感信息。企业还被鼓励投资于与 AI 技术相关的信任、风险和安全管理（TRiSM）产品和能力。这包括 AI 治理、数据安全治理、提示过滤和红 action，以及合成生成非结构化数据。Gartner 预测，到2026年，实施 AI TRiSM 控制的企业将减少至少50% 的不准确信息，从而降低错误决策的风险。划重点:🔍 超过40% 的 AI 数据泄露将由生成式 AI 误用引发。🛡️ 企业需加强数据治理，确保合规与安全。📈 投资 AI 相关的信任、风险和安全管理产品，能显著减少错误信息的产生。
