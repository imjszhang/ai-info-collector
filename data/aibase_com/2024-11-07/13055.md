# OpenAI推GPT-4o预测输出功能：响应速度提升5倍，但更贵了

**发布日期**: 2024年11月7号 9:22

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/13055)

## 内容

OpenAI近日推出了一项重要更新，为GPT-4o模型引入"预测输出"（Predicted Outputs）功能。这项创新技术显著提升了模型的响应速度，在特定场景下最高可达到原有速度的5倍，为开发者带来全新的效率体验。这项由OpenAI与FactoryAI联合开发的功能，其核心优势在于能够绕过已知内容的重复生成过程。在实际应用中，特别是在更新博客文章、迭代现有回复或重写代码等任务上表现出色。根据FactoryAI提供的数据显示，在编程任务中，响应时间缩短了2至4倍，将原本需要70秒的任务压缩至20秒内完成。目前，该功能仅通过API形式向开发者开放，支持GPT-4o和GPT-4mini两个模型。实际使用反馈积极，多位开发者已展开测试并分享使用体验。Firecrawl创始人Eric Ciarla在进行SEO内容转换时表示:"速度提升显著，使用方式简单直接。"技术层面上，预测输出功能的工作原理是识别和复用可预见的内容部分。OpenAI官方文档举例说明，在代码重构等场景中，如将C#代码中的"Username"属性修改为"Email"时，通过将整个类文件作为预测文本输入，可以大幅提升生成速度。然而，该功能也存在一些使用限制和注意事项。除了模型支持的限制外，某些API参数在使用预测输出时不可用，包括大于1的n值、logprobs以及大于0的presence_penalty和frequency_penalty等。值得注意的是，这项功能在提供更快响应速度的同时，也带来了轻微的成本增加。根据用户测试数据，同一任务在使用预测输出功能后，虽然处理时间从5.2秒减少到3.3秒，但费用从0.1555美分上升至0.2675美分。这是因为OpenAI对预测时提供的非最终完成部分的tokens同样按照完成tokens费率收费。尽管成本略有提升，但考虑到显著的效率提升，这项功能仍然具有相当的应用价值。开发者可通过OpenAI官方文档获取更详细的技术说明和使用指南。OpenAI 官方文档:https://platform.openai.com/docs/guides/latency-optimization#use-predicted-outputs
