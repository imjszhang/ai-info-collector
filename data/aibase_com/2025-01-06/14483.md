# ​字节跳动推出新 AI 模型INFP，让静态人像照片 “开口说话”

**发布日期**: 2025年1月6号 10:22

![新闻图片](https://pic.chinaz.com/thumb/2025/0106/25010610215096682792.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14483)

## 内容

近日，字节跳动公司宣布推出一种名为 INFP 的人工智能系统，能够让静态的人物肖像照片通过音频输入实现 “说话” 和反应。与传统技术不同，INFP 无需手动指定说话和倾听的角色，系统可以根据对话的流动自动判断角色。INFP 的工作流程分为两个主要步骤。第一步，称为 “基于运动的头部模仿”，该系统通过分析人们在对话中的面部表情和头部运动，从视频中提取细节。这些运动数据会被转化为可以用于后续动画的格式，使静态照片能够与原始人物的运动相匹配。第二步是 “音频引导运动生成”，系统则根据音频输入生成自然的运动模式。研究团队开发了一种 “运动引导器”，该工具通过分析对话双方的音频，创建出说话和倾听的运动模式。随后，名为扩散变换器的 AI 组件对这些模式进行逐步优化，从而生成流畅且真实的运动，完美契合音频内容。为了对系统进行有效训练，研究团队还建立了一个名为 DyConv 的对话数据集，汇集了200多个小时的真实对话视频。与现有的对话数据库（如 ViCo 和 RealTalk）相比，DyConv 在情感表达和视频质量方面具有独特优势。字节跳动表示，INFP 在多个关键领域的表现优于现有工具，特别是在与语音匹配的唇部运动、保留个体面部特征以及创造多样化自然动作方面。此外，该系统在生成仅听对话者的视频时同样表现出色。虽然目前 INFP 仅支持音频输入，研究团队正在探索将系统扩展到图像和文本的可能性，未来目标是能够创建出人物全身的真实动画。然而，考虑到这类技术可能被用于制造虚假视频和传播错误信息，研究团队计划将核心技术限制在研究机构使用，类似于微软对其先进语音克隆系统的管理。这项技术是字节跳动更广泛 AI 战略的一部分，依托其旗下的热门应用 TikTok 和 CapCut，字节跳动拥有广阔的 AI 创新应用平台。项目入口:https://grisoon.github.io/INFP/划重点:🎤 INFP 可以让静态人像通过音频实现 “说话”，自动判断对话角色。🎥 该系统通过两个步骤工作:首先提取人类对话中的运动细节，其次将音频转换为自然的运动模式。📊 字节跳动的 DyConv 数据集包含超过200小时的高质量对话视频，帮助提升系统性能。
