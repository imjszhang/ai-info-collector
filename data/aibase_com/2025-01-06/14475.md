# 阿里团队出品！妆容迁移技术SHMT：提供化妆参考图就能给你上妆

**发布日期**: 2025年1月6号 9:30

![新闻图片](https://upload.chinaz.com/2025/0106/6387175257748125682810128.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14475)

## 内容

近日，阿里巴巴达摩院的研究团队发布了一项重要研究成果，名为 “SHMT:自监督层次化妆转移”，该论文已被国际顶级学术会议 NeurIPS2024接收。这项研究展示了一种新的化妆效果转移技术，利用潜在扩散模型（Latent Diffusion Models）来实现化妆图像的精准生成，为化妆应用和图像处理领域注入了新活力。简单的说，SHMT是一项妆容迁移技术，只要一个化妆的参考图，和一张目标角色照片，就可以把妆容效果迁移到该目标脸上。团队在项目中采用了开源的方式，发布了训练代码、测试代码以及预训练模型，使得研究人员能够更方便地进行相关研究和开发。在模型的搭建过程中，团队推荐用户创建一个名为 “ldm” 的 conda 环境，并通过提供的环境文件快速完成设置。此外，研究中选用了 VQ-f4作为预训练的自编码模型，用户需将其下载并放入指定的检查点文件夹，以便顺利开始推理。数据准备是 SHMT 模型成功运行的关键。研究团队建议下载 “BeautyGAN” 提供的化妆迁移数据集，并将不同的化妆和非化妆图像进行整合。同时，面部解析和3D 面部数据的准备也至关重要，相关工具和数据路径在研究中进行了详细说明，以确保用户能够有效地进行数据准备。在模型训练与推理方面，研究团队提供了详细的命令行脚本，用户可根据自身需求调整参数。团队还特别强调了数据结构的重要性，提供了清晰的目录结构示例，指导用户如何准备数据。SHMT 模型的推出，标志着自监督学习在化妆效果迁移领域的成功应用，未来可能在美容、美妆和图像处理等行业得到广泛应用。这项研究不仅展示了技术的潜力，同时也为相关领域的深入研究打下了坚实的基础。项目入口:https://github.com/Snowfallingplum/SHMT划重点:1. 🎓 SHMT 模型利用潜在扩散模型实现化妆效果转移，已被 NeurIPS2024接收。2. 🔧 团队提供完整的开源代码和预训练模型，便于研究人员进行应用与改进。3. 📂 数据准备和参数调整至关重要，研究中详细指导了操作流程和目录结构。
