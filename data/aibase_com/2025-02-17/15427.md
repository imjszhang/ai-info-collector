# 月之暗面解密o1:Long-CoT是关键，模型思考需要"放长线"

**发布日期**: 2025年2月17号 14:37

![新闻图片](https://pic.chinaz.com/picmap/thumb/202405240907574564_1.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/15427)

## 内容

月之暗面研究员Flood Sung近日发表万字长文，首次详细披露了k1.5模型的研发思路，并就OpenAI o1模型带来的技术启示进行深度反思。据Flood Sung介绍，Long-CoT（长链条思维）的重要性其实早在一年多前就已被月之暗面联合创始人Tim周昕宇验证。通过使用小型模型训练多位数运算，并将细粒度运算过程转化为长链条思维数据进行SFT(有监督微调)，就能获得显著效果。然而，受限于成本考虑，月之暗面此前将重点放在了Long Context（长文本输入）的优化上。Flood Sung解释道，Long Context主要处理输入端，借助Prefill预填充和Mooncake技术，可以较好地控制成本和速度。相比之下，Long-CoT侧重输出端，需要更高的成本和更长的处理时间。但OpenAI o1的发布让团队重新思考了技术方向的优先级。"性能才是最重要的，"Flood Sung表示，"成本和速度会随着技术进步不断优化，关键是要先实现突破性能。"基于这一认识，月之暗面已开始全面推进Long-CoT研究，致力于让模型实现更接近人类的自由思考能力。此次技术解密文章的发布，标志着月之暗面已开始系统性地对标o1模型，并在相关领域展开实质性研究。解密o1破解过程的万字长文:https://mp.weixin.qq.com/s/sJmT-tM3A-mglZ1d4OI80A
