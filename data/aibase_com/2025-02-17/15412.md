# OpenAI调整策略，力求在内容审查与自由言论之间找到平衡

**发布日期**: 2025年2月17号 10:26

![新闻图片](https://pic.chinaz.com/picmap/202412271704353969_1.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/15412)

## 内容

OpenAI 近期宣布了一项重要的政策更新，旨在改变其人工智能模型的训练方式，强调 “知识自由” 的重要性，无论话题多么具有挑战性或争议性。这一变化意味着，ChatGPT 将能更全面地回答问题，提供更多视角，减少拒绝讨论某些话题的情况。在新的187页模型规范中，OpenAI 提出了一个新的指导原则:不要撒谎，既不要发表不真实的陈述，也不要省略重要的上下文。新设立的 “共同寻求真相” 部分表示，OpenAI 希望 ChatGPT 在面对争议性话题时能够保持中立，不偏向任何一方。这意味着，ChatGPT 会在讨论如 “黑人的命也是命” 与 “所有人的命也是命” 时，尽量呈现两者观点，而不是拒绝回答或选择立场。图源备注：图片由AI生成尽管 OpenAI 坚持其不进行 “审查” 的立场，但部分保守派人士却认为，OpenAI 在过去数月中确实存在内容审查的问题，尤其是他们觉得 AI 的偏见明显倾向于中左派。OpenAI 首席执行官山姆・阿尔特曼（Sam Altman）也承认，ChatGPT 的偏见是一个需要解决的 “缺陷”。不过，OpenAI 的新政策也并非无底线，ChatGPT 仍会拒绝回答某些明显错误或不当的问题。随着政策的变化，OpenAI 希望用户能够获得更多的言论自由，甚至移除了对违反政策用户的警告提示。此举被视为为了减少用户感受到的 “审查” 压力。而在更大的背景下，硅谷的价值观正在发生转变。许多公司开始缩减过去以多样性、公平与包容性为核心的政策，OpenAI 似乎也在逐步放弃这些立场。正如其他大型科技公司一样，OpenAI 正面临着与新特朗普政府的关系影响，以及在信息领域与谷歌的竞争。在这个充满争议与挑战的环境中，如何平衡自由言论与内容的安全性，成为了 OpenAI 及其他科技公司的重要议题。
