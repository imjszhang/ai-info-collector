# Light-A-Video ：无需训练实现视频重新打光

**发布日期**: 2025年2月17号 10:22

![新闻图片](https://upload.chinaz.com/2025/0217/6387538448148563487945343.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/15411)

## 内容

近年来，图像重光照技术的进步得益于大规模数据集和预训练的扩散模型，使得一致性光照的应用变得更加普遍。然而，在视频重光照领域，由于训练成本高昂以及缺乏多样化和高质量的视频重光照数据集，进展相对缓慢。仅仅将图像重光照模型逐帧应用于视频，会导致多种问题，如光源不一致和重光照外观不一致，最终导致生成的视频出现闪烁现象。为了解决这一问题，研究团队提出了 Light-A-Video，这是一种无需训练的、能够实现时间上平滑视频重光照的方法。Light-A-Video 借鉴了图像重光照模型，并引入了两个关键模块以增强光照一致性。首先，研究人员设计了一个一致光注意力（Consistent Light Attention，CLA）模块，该模块增强了自注意力层内的跨帧交互，以稳定背景光源的生成。其次，基于光传输独立性的物理原理，研究团队采用线性融合策略，将源视频的外观与重光照外观进行混合，采用渐进光融合（Progressive Light Fusion，PLF）策略，确保光照在时间上的平滑过渡。在实验中，Light-A-Video 展示了显著改善重光照视频的时间一致性，同时保持了图像质量，确保了跨帧的光照过渡的一致性。框架中展示了源视频的处理过程:首先对源视频进行噪声处理，然后经过 VDM 模型进行逐步去噪。在每一步中，预测的无噪声组件代表了 VDM 的去噪方向，并作为一致目标。在此基础上，一致光注意力模块注入独特的光照信息，将其转变为重光照目标。最后，渐进光融合策略将两个目标合并，形成融合目标，从而为当前步骤提供了更精细的方向。Light-A-Video 的成功不仅展示了视频重光照技术的潜力，也为未来的相关研究指明了方向。https://bujiazi.github.io/light-a-video.github.io/划重点:🌟 Light-A-Video 是一种无需训练的技术，旨在实现视频重光照的时间一致性。🎥 采用一致光注意力模块和渐进光融合策略，解决了视频重光照中的光源不一致问题。📈 实验表明，Light-A-Video 显著提高了重光照视频的时间一致性与图像质量。
