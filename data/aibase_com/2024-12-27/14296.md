# 智谱A​I开源Agent任务模型CogAgent-9B：通过屏幕截图预判操作

**发布日期**: 2024年12月27号 1:16

![新闻图片](https://upload.chinaz.com/2024/1227/6387088776329285667643024.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14296)

## 内容

智谱AI旗下的GLM-PC基座模型CogAgent-9B现已开源，以促进大模型Agent生态的发展。CogAgent-9B是基于GLM-4V-9B训练而成的专用Agent任务模型，能够仅通过屏幕截图作为输入，根据用户指定的任意任务结合历史操作，预测下一步的GUI操作。这一模型的普适性使其可广泛应用于个人电脑、手机、车机设备等多种基于GUI交互的场景。与2023年12月开源的第一版CogAgent模型相比，CogAgent-9B-20241220在GUI感知、推理预测准确性、动作空间完善性、任务普适性和泛化性等方面均有显著提升，并支持中英文双语的屏幕截图和语言交互。CogAgent的输入仅包含用户的自然语言指令、已执行历史动作记录和GUI截图，无需任何文本形式表征的布局信息或附加元素标签信息。输出则涵盖思考过程、下一步动作的自然语言描述、下一步动作的结构化描述以及下一步动作的敏感性判断。在性能测试中，CogAgent-9B-20241220在多个数据集上取得了领先结果，展现了其在GUI定位、单步操作、中文step-wise榜单和多步操作等方面的优势。智谱技术的这一举措，不仅推动了大模型技术的发展，也为视障IT从业者提供了新的工具和可能性。代码:https://github.com/THUDM/CogAgent模型:Huggingface: https://huggingface.co/THUDM/cogagent-9b-20241220魔搭社区:https://modelscope.cn/models/ZhipuAI/cogagent-9b-20241220
