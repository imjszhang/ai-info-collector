# ​DeepSeek-V3：超大开源AI模型发布，性能超越Llama和Qwen

**发布日期**: 2024年12月27号 1:35

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14298)

## 内容

2024年12月26日，中国人工智能初创公司DeepSeek发布了其最新的超大模型DeepSeek-V3，这一模型以其开放源代码技术和创新挑战领先AI供应商而闻名。DeepSeek-V3拥有671B个参数，并采用专家混合架构（mixture-of-experts architecture）来激活特定参数，以准确高效地处理给定任务。根据DeepSeek提供的基准测试，这一新模型已经超越了包括Meta的Llama3.1-405B在内的领先开源模型，并且与Anthropic和OpenAI的封闭模型性能相近。DeepSeek-V3的发布标志着开源AI与封闭源AI之间的差距进一步缩小。DeepSeek，最初是中国量化对冲基金High-Flyer Capital Management的一个分支，希望这些发展能为人工通用智能（AGI）铺平道路，届时模型将能够理解或学习任何人类能够执行的智力任务。DeepSeek-V3的主要特点包括:与前身DeepSeek-V2一样，新模型基于多头潜在注意力（MLA）和DeepSeekMoE的基本架构，确保了高效的训练和推理。公司还推出了两项创新:辅助无损失负载平衡策略和多令牌预测（MTP），后者允许模型同时预测多个未来令牌，提高了训练效率，并使模型运行速度提高三倍，每秒生成60个令牌。在预训练阶段，DeepSeek-V3训练了14.8T高质量和多样化的令牌，并进行了两阶段的上下文长度扩展，最终进行了监督式微调（SFT）和强化学习(RL)的后训练，以使模型与人类偏好对齐并进一步释放其潜力。在训练阶段，DeepSeek采用了多种硬件和算法优化，包括FP8混合精度训练框架和DualPipe算法进行流水线并行，降低了训练成本。DeepSeek-V3的整个训练过程声称在2788K H800GPU小时或大约557万美元内完成，远低于通常用于预训练大型语言模型的数亿美元。DeepSeek-V3已成为市场上最强的开源模型。公司进行的多项基准测试显示，它在大多数基准测试中超越了封闭源GPT-4o，除了以英语为焦点的SimpleQA和FRAMES，在这两个测试中OpenAI模型分别以38.2和80.5的得分领先（DeepSeek-V3得分分别为24.9和73.3）。DeepSeek-V3在中文和数学基准测试中的表现尤为突出，在Math-500测试中得分为90.2，其次是Qwen的80分。目前，DeepSeek-V3的代码可在GitHub上以MIT许可证获得，模型根据公司的模型许可证提供。企业还可以通过DeepSeek Chat（类似ChatGPT的平台）测试新模型，并访问API进行商业使用。DeepSeek将提供与DeepSeek-V2相同价格的API，直至2月8日。之后，将收取每百万输入令牌0.27美元(缓存命中每百万令牌0.07美元)和每百万输出令牌1.10美元的费用。划重点:🌟 DeepSeek-V3发布，性能超越Llama和Qwen。🔧 采用671B参数和专家混合架构，提高效率。🚀 创新包括无损失负载平衡策略和多令牌预测，提升速度。💼 训练成本大幅降低，推动开源AI发展。
