# 成本不足50美元！研究人员训练出AI推理模型s1，媲美OpenAI的o1

**发布日期**: 2025年2月6号 9:27

![新闻图片](https://upload.chinaz.com/2025/0206/6387443085968521418682060.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/15090)

## 内容

近期，斯坦福大学和华盛顿大学的 AI 研究人员成功训练出了一款名为 s1的 AI 推理模型，训练成本不足50美元，所需的云计算信用额度也非常低。这项研究成果于上周五发布，表明 s1在数学和编程能力测试上表现不逊于 OpenAI 的 o1模型和 DeepSeek 的 R1模型。s1的代码和数据已在 GitHub 上公开，供其他研究者使用。研究团队表示，他们从一个现成的基础模型出发，通过蒸馏技术进行微调，以提取出所需的推理能力。s1的蒸馏过程使用了谷歌的 Gemini2.0Flash Thinking Experimental 模型，这种方法与加州大学伯克利分校的研究人员上个月训练另一款 AI 推理模型时采用的方式相似，后者的训练成本约为450美元。这一成果让许多人感到振奋，尤其是在如今的 AI 领域，研究者们能够在没有巨额资金支持的情况下仍能进行创新。然而，s1的出现也引发了对 AI 模型商品化的深思。若任何人都可以以相对较低的成本复制出多百万美元的模型，那么这些大公司的护城河究竟在哪里呢?显然，大型 AI 实验室对此并不满意，OpenAI 曾指控 DeepSeek 不当使用其 API 数据进行模型蒸馏。s1的研究团队希望能找到一种简单的方法来实现强大的推理性能，同时提升 “测试时间扩展” 能力，即让 AI 模型在回答问题之前有更多思考时间。这些都是 OpenAI 的 o1模型所取得的突破，DeepSeek 及其他 AI 实验室也尝试用不同的方法进行复制。s1的研究表明，通过一个相对小的数据集，使用监督微调 （SFT） 方法可以有效蒸馏推理模型，而这种方法通常比 DeepSeek 采用的大规模强化学习方法更便宜。谷歌也提供了对 Gemini2.0Flash Thinking Experimental 的免费访问，但该平台有每日使用限制，并且其条款禁止逆向工程其模型以开发竞争服务。为了训练 s1，研究人员构建了一个包含1000个经过精心挑选的问题及其对应答案的数据集，同时附上了问题背后的 “思考” 过程。训练过程使用了16个 Nvidia H100GPU，耗时不足30分钟。根据研究人员的介绍，他们如今只需约20美元就能租到所需的计算资源。此外，研究团队还使用了一个巧妙的技巧，让 s1在推理时添加 “等待” 一词，从而提升答案的准确性。在未来的2025年，Meta、谷歌和微软计划在 AI 基础设施上投资数千亿美元，其中部分资金将用于训练下一代 AI 模型。尽管蒸馏技术在以较低成本再现 AI 模型的能力上展现出良好效果，但它并没有显著提升新的 AI 模型的表现。论文:https://arxiv.org/pdf/2501.19393代码:https://github.com/simplescaling/s1划重点:🌟 s1模型的训练成本不足50美元，表现媲美顶尖推理模型。🛠️ 研究团队通过蒸馏技术，从现成模型中提取推理能力，训练过程快速高效。🚀 大型 AI 实验室对低成本复制模型的情况表示担忧，未来投资将集中在 AI 基础设施上。
