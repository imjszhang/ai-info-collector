# DeepSeek-R1 模型幻觉问题严重，推理能力与准确性面临挑战

**发布日期**: 2025年2月6号 10:57

![新闻图片](https://pic.chinaz.com/picmap/202502051558227846_7.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/15102)

## 内容

近日，Vectara 的机器学习团队对 DeepSeek 系列的两款模型进行了深入的幻觉测试，结果显示，DeepSeek-R1的幻觉率高达14.3%，显著高于其前身 DeepSeek-V3的3.9%。这表明，在增强推理的过程中，DeepSeek-R1产生了更多不准确或与原始信息不一致的内容。该结果引发了对推理增强大语言模型（LLM）产生幻觉率的广泛讨论。图源备注:图片由AI生成，图片授权服务商Midjourney研究团队指出，推理增强模型可能会比普通的大语言模型更容易产生幻觉。这一现象在 DeepSeek 系列与其他推理增强模型的比较中表现得尤为明显。以 GPT 系列为例，推理增强的 GPT-o1与普通版 GPT-4o 之间的幻觉率差异，也验证了这一推测。为了评估这两款模型的表现，研究人员使用了 Vectara 的 HHEM 模型和 Google 的 FACTS 方法进行判断。HHEM 作为专门的幻觉检测工具，在捕捉 DeepSeek-R1的幻觉率增加时表现出较高的灵敏度，而 FACTS 模型在这方面的表现则相对逊色。这提示我们，可能 HHEM 比 LLM 作为标准更加有效。值得注意的是，DeepSeek-R1尽管在推理能力上表现出色，但却伴随着更高的幻觉率。这可能与推理增强模型所需处理的复杂逻辑有关。随着模型推理的复杂性增加，生成内容的准确性反而可能受到影响。研究团队还强调，若 DeepSeek 在训练阶段能够更关注减少幻觉问题，或许能实现推理能力与准确性之间的良好平衡。虽然推理增强模型通常表现出更高的幻觉率，但这并不意味着它们在其他方面不具优势。对于 DeepSeek 系列来说，仍需在后续的研究和优化中，解决幻觉问题以提升整体模型性能。参考资料：https://www.vectara.com/blog/deepseek-r1-hallucinates-more-than-deepseek-v3
