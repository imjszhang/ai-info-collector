# 谷歌新AI模型PaliGemma2引发情绪识别争议:隐患与挑战并存

**发布日期**: 2024年12月6号 9:23

![新闻图片](https://upload.chinaz.com/2024/1206/6386907362788698703231685.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/13737)

## 内容

谷歌日前发布了其新一代人工智能模型——PaliGemma2，该技术能分析图像并生成标题，同时回答关于照片中人物的情感和行动等问题。PaliGemma2基于谷歌的 Gemma 开放模型系列，提供比传统物体识别更为深刻的图像描述，能够识别情绪并生成符合上下文的详细描述。然而，尽管这一技术看似突破性创新，专家却对其潜在的伦理和社会影响提出了严重警告。情绪识别并非PaliGemma2的标准功能，而是通过微调实现的。尽管谷歌表示其已进行了“广泛测试”，并且在人口统计学偏见方面表现优于行业基准，专家们仍对该技术的可靠性表示担忧。牛津大学的桑德拉·沃赫特教授认为，“通过人工智能来‘读懂’人类情绪存在重大问题”，并且这一过程过于依赖假设，可能导致误判和偏见。情绪识别技术长期以来一直是技术界争议的焦点。虽然早期研究如保罗·艾克曼的情绪理论提出了六种基本情绪，但后续的研究表明，不同文化和背景下的情绪表达差异巨大。英国玛丽女王大学的迈克·库克研究员指出，“情绪体验的复杂性使得情绪检测几乎不可能做到准确”。此外，研究表明，现有的面部表情分析系统常常对某些情感产生偏见，如微笑或不同种族面部表情的差异。随着情绪识别技术逐渐商业化，其可能带来的滥用风险引起了各方关注。部分专家担心，这类技术可能被用于执法、招聘等领域，进一步加剧社会的不平等。欧盟的人工智能法案已经针对情绪识别技术提出了严格的限制，尤其是在高风险环境中的应用。谷歌则坚称，PaliGemma2在测试阶段已充分考虑了伦理和安全问题，尤其是儿童和内容安全方面。然而，这些保证是否足够，仍需受到严格审视。AI Now Institute的Heidy Khlaaf博士表示，情绪识别不仅是视觉问题，还涉及深层的社会和文化背景，“仅凭面部特征无法准确推断情绪”。随着这一技术的公开发布，PaliGemma2不仅将推动人工智能在图像理解领域的应用，也将对社会伦理和数据隐私提出新的挑战，亟需相关监管机构的关注和干预。
