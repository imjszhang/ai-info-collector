# 谷歌发布PaliGemma 2:AI能"读懂"情绪？专家质疑其科学性和伦理风险

**发布日期**: 2024年12月6号 10:11

![新闻图片](https://upload.chinaz.com/2024/1206/6386907667185161193332755.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/13740)

## 内容

谷歌近日推出了全新的AI模型家族PaliGemma2，其最引人注目的功能是声称能够通过图像分析"识别"人类情绪。这一宣称迅速引发了学术界和技术伦理专家的广泛讨论和严重质疑。这款基于Gemma开放模型的AI系统能够生成详细的图像描述，不仅仅停留在简单的物体识别，还试图描述图像中人物的行为和情感。然而，多位权威专家对这一技术的科学性和潜在风险提出了严重警告。来自牛津互联网研究所的数据伦理教授桑德拉·瓦赫特直言不讳地指出，试图通过AI"读取"人类情绪如同"问魔法八号球寻求建议"。这一比喻生动地揭示了情绪识别技术的荒谬之处。事实上，情绪识别的科学基础本身就极其脆弱。早期由心理学家保罗·埃克曼提出的六种基本情绪理论已经被后续研究广泛质疑。不同文化背景的人表达情感的方式存在显著差异，这使得通用的情绪识别几乎成为不可能完成的任务。来自玛丽女王大学的AI研究员迈克·库克更直接地表示，情绪检测在普遍意义上是不可能的。尽管人类常常相信自己能够通过观察判断他人的情绪，但这种能力远比想象的复杂和不可靠。更令人担忧的是，这类AI系统往往存在严重的偏见。多项研究显示，面部分析模型可能会对不同肤色的人群产生不同的情绪判断，这无疑会加剧现有的社会歧视。尽管谷歌声称对PaliGemma2进行了广泛的测试，并在一些基准测试中表现良好，但专家们对此仍持严重怀疑态度。他们认为，仅凭有限的测试根本无法全面评估这种技术可能带来的伦理风险。最危险的是，这种开放模型可能被滥用于就业、教育、执法等关键领域，从而对弱势群体造成实际伤害。正如瓦赫特教授所警告的，这可能导致一个可怕的"失控"未来:人们的就业、贷款和教育机会将由一个不可靠的AI系统的"情绪判断"决定。在人工智能快速发展的今天，技术创新固然重要，但伦理和安全同样不可忽视。PaliGemma2的出现，再次凸显了我们需要对AI技术保持清醒和批判性的审视。
