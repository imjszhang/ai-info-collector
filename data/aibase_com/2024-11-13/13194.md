# 谷歌Gemini API 现已兼容 OpenAI，助力开发者轻松切换

**发布日期**: 2024年11月13号 11:31

![新闻图片](https://upload.chinaz.com/2024/1113/6386709422837233594854238.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/13194)

## 内容

谷歌近日宣布推出其 Gemini API 的新端点，旨在帮助已经采用 OpenAI 解决方案的开发者更轻松地切换到 Gemini。这一新端点目前仍处于测试阶段，仅提供部分 OpenAI 功能的支持。根据谷歌的介绍，该新端点可以在使用直接的 REST 调用或 OpenAI 官方 SDK 的情况下替代 OpenAI 的端点。例如，如果你有一个使用 OpenAI SDK（比如 Python）编写的程序，可以通过如下代码更改初始化，使用谷歌的模型:from openai import OpenAIclient = OpenAI （api_key="gemini_api_key"，base_url="https://generativelanguage.googleapis.com/v1beta/openai/"）在代码中，开发者需要提供 Gemini API 密钥，密钥可以直接写在代码中或通过 OPENAI_API_KEY 环境变量传递。要生成文本，可以使用聊天补全 API，如下所示，指定希望使用的 Gemini 模型名称:response = client.chat.completions.create （model="gemini-1.5-flash"，n=1，messages=[{"role": "system"， "content": "你是一个有帮助的助手。"}，{"role": "user"，"content": "给我解释一下 AI 是如何工作的"}]）print （response.choices [0].message）此外，新的 Gemini 端点还支持 OpenAI 的嵌入 API，用于测量文本字符串之间的相关性。简而言之，嵌入 API 将文本映射为浮点数的向量，开发者可以利用这些向量来搜索特定值、对文本进行聚类、检测异常和提供推荐等。以下代码片段展示了如何在 Gemini 中使用这一功能:response = client.embeddings.create （input="您的文本字符串在这里"，model="text-embedding-004"）print （response.data [0].embedding）目前，聊天补全 API 和嵌入 API 是唯一可以通过新 OpenAI 端点在 Gemini 模型上使用的 OpenAI 功能。此外，图像上传和结构化输出的支持也仅限于有限的功能。谷歌表示，他们计划添加更多 OpenAI 的功能，以便开发者能够更方便地将 Gemini 作为 OpenAI 的替代方案，但具体的时间框架尚不明确。在 Reddit 的讨论中，评论者对谷歌的这一举措表示赞赏，认为这为 OpenAI API 用户提供了一种逃避锁定的解决方案，尽管距离实现一个标准 API 以便于在不同模型提供者之间轻松切换仍有很长的路要走。作为更通用的方法，vLLM 项目旨在支持各种生成和嵌入模型，并提供一个与 OpenAI 兼容的服务器。借助 vLLM，开发者可以使用 Mistral、Llama、Llava 以及当前可用的许多其他主要模型。官方介绍:https://developers.googleblog.com/en/gemini-is-now-accessible-from-the-openai-library/划重点:🌟 谷歌推出 Gemini API 新端点，帮助开发者更轻松地切换到 Gemini。🔑 新端点支持 OpenAI 的聊天补全和嵌入 API，但功能尚不完全。🛠️ vLLM 项目提供多种模型的支持，提升 API 灵活性。
