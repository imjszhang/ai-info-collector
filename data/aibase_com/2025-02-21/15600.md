# DDN 推出 Infinia 2.0对象存储，加速AI数据处理速度

**发布日期**: 2025年2月21号 14:33

![新闻图片](https://pic.chinaz.com/picmap/202304261750583758_2.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/15600)

## 内容

在最近的发布会上，数据动力公司（DDN）宣布了其最新的 Infinia2.0对象存储系统，专为人工智能(AI)训练和推理而设计。该系统声称可以实现高达100倍的 AI 数据加速和10倍的云数据中心成本效率提升，吸引了众多行业关注。DDN 的首席执行官兼联合创始人亚历克斯・布扎里（Alex Bouzari）表示:“全球500强企业中有85家在使用 DDN 的数据智能平台来运行他们的 AI 和高性能计算(HPC)应用。Infinia 将帮助客户在数据分析和 AI 框架方面实现更快的模型训练和实时洞察，同时确保 GPU 效率和能耗的未来适应性。”图源备注：图片由AI生成，图片授权服务商MidjourneyDDN 的联合创始人、总裁保罗・布洛赫（Paul Bloch）也补充道:“我们的平台已经在全球一些最大的 AI 工厂和云环境中投入使用，证明了其支持关键 AI 操作的能力。” 据悉，Elon Musk 的 xAI 也是 DDN 的客户之一。在 Infinia2.0的设计中，AI 数据存储是核心。首席技术官斯文・厄梅（Sven Oehme）强调:“AI 工作负载需要实时数据智能，消除瓶颈，加速工作流程，并在复杂的模型列举、预训练和后训练、增强生成(RAG)、Agentic AI 以及多模态环境中无缝扩展。”Infinia2.0旨在最大化 AI 的价值，同时提供实时数据服务、高效的多租户管理、智能自动化和强大的 AI 原生架构。该系统具备事件驱动的数据移动、多租户、硬件无关设计等特性，保证99.999% 的正常运行时间，并实现最高10倍的始终在线数据减缩、容错网络擦除编码和自动化的服务质量（QoS）。Infinia2.0与 Nvidia 的 Nemo、NIMS 微服务、GPU、Bluefield3DPU 和 Spectrum-X 网络相结合，加速 AI 数据管道的效率。DDN 声称，Infinia 的带宽可达到 TBps，延迟低于毫秒，性能远超 AWS S3Express。其他令人瞩目的参数包括，基于独立基准测试，Infinia 在 AI 数据加速、AI 工作负载处理速度、元数据处理和对象列表处理方面均实现了100倍的提升，且在 AI 模型训练和推理查询速度上快25倍。Infinia 系统支持从 TB 到 EB 的规模扩展，能够支持超过100，000个 GPU 和100万个同时客户端，为大规模 AI 创新提供了坚实基础。DDN 强调，其系统在实际数据中心和云部署中表现出色，能够在从10到超过100，000个 GPU 的范围内实现无与伦比的效率和成本节约。超级微型公司（Supermicro）的首席执行官查尔斯・梁(Charles Liang)表示:“通过将 DDN 的数据智能平台 Infinia2.0与 Supermicro 的高端服务器解决方案相结合，两家公司合作建设了全球最大的 AI 数据中心之一。” 这一合作关系可能与 xAI 的 Colossus 数据中心扩展有关。
