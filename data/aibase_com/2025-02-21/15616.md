# Sakana AI发布“AI CUDA工程师”：自动化优化CUDA内核，速度提升高达100倍

**发布日期**: 2025年2月21号 17:26

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/15616)

## 内容

日本人工智能初创公司Sakana AI宣布推出“AI CUDA工程师”（AI CUDA Engineer），这一创新性的AI智能体系统旨在自动化生产高度优化的CUDA内核，显著提升机器学习操作的运行效率。根据X平台上的最新消息，该系统通过进化的大型语言模型(LLM)驱动代码优化技术，将常见PyTorch操作的运行速度提高了10至100倍，标志着AI技术在GPU性能优化领域的重大突破。Sakana AI表示，CUDA内核作为GPU计算的核心，直接编写和优化通常需要深厚的专业知识和高技术门槛，而现有框架如PyTorch虽然使用便捷，但在性能上往往无法与手动优化的内核媲美。“AI CUDA工程师”通过智能化的工作流程解决了这一难题:它不仅能将PyTorch代码自动转化为高效的CUDA内核，还通过进化算法进行性能调优，甚至能融合多个内核以进一步提升运行时效率。X用户@shao__meng将这一技术比喻为“给AI开发装上了自动变速箱”，让普通代码能够“自动升级为赛车级性能”。另一位用户@FinanceYF5也在帖子中指出，该系统的推出展示了AI自优化的潜力，可能为未来的计算资源使用效率带来革命性提升。Sakana AI此前已因“AI Scientist”等项目在业界崭露头角，此次“AI CUDA工程师”的发布进一步凸显了其在AI自动化领域的雄心。公司声称，该系统已成功生成并验证了超过17，000个CUDA内核，覆盖多种PyTorch操作，且公开的数据集将为研究人员和开发者提供宝贵资源。业内人士认为，这一技术不仅降低了高性能GPU编程的门槛，还可能推动人工智能模型的训练和部署效率迈上新台阶。信息参考：https://x.com/FinanceYF5/status/1892856847780237318
