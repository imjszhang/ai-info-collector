# ​MIT、 DeepMind研究揭示视觉语言模型无法理解否定表达的原因

**发布日期**: 2025年1月20号 14:04

![新闻图片](https://upload.chinaz.com/2025/0120/6387297857568569682216620.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14847)

## 内容

在多模态任务中，视觉语言模型（VLMs）起着至关重要的作用，如图像检索、图像说明和医学诊断等。这些模型的目标是将视觉数据与语言数据进行对齐，以实现更高效的信息处理。然而，目前的 VLMs 在理解否定方面仍面临重大挑战。否定在许多应用中至关重要，例如区分 “没有窗户的房间” 和 “有窗户的房间”。尽管 VLMs 取得了显著进展，但在处理否定陈述时，现有模型的表现却大幅下降。这种限制尤其在安全监控和医疗保健等高风险领域中显得尤为重要。现有的 VLMs，如 CLIP，采用共享嵌入空间来对齐视觉和文本表示。虽然这些模型在跨模态检索和图像说明等任务上表现出色，但在处理否定语句时却显得力不从心。此问题的根源在于预训练数据的偏差，训练数据主要由肯定示例构成，导致模型将否定与肯定陈述视为同义。因此，现有的基准测试，如 CREPE 和 CC-Neg，采用了简单的模板示例，无法真实反映自然语言中否定的丰富性和深度。这使得 VLMs 在进行精准的语言理解应用时，如查询医学影像数据库中的复杂条件，面临巨大挑战。为了解决这些问题，来自麻省理工学院、谷歌 DeepMind 和牛津大学的研究人员提出了 NegBench 框架，用于评估和改进 VLMs 对否定的理解能力。该框架评估两个基本任务:检索与否定（Retrieval-Neg），检验模型根据肯定和否定描述检索图像的能力;多项选择题与否定(MCQ-Neg)，评估模型在微妙理解上的表现。NegBench 使用大量合成数据集，如 CC12M-NegCap 和 CC12M-NegMCQ，包含数百万个涵盖丰富否定场景的标题，从而提高模型的训练和评估效果。通过结合真实和合成的数据集，NegBench 有效克服了现有模型的限制，显著提高了模型的性能和泛化能力。经过微调的模型在检索和理解任务上都表现出显著改善，特别是在处理否定查询时，模型的召回率提高了10%。在多项选择任务中，准确率提升了多达40%，显示出在微妙的肯定和否定标题之间进行区分的能力大大增强。NegBench 的提出，填补了 VLMs 在理解否定方面的关键空白，为构建更强大的人工智能系统铺平了道路，尤其在医学诊断和语义内容检索等关键领域具有重要意义。论文:https://arxiv.org/abs/2501.09425代码:https://github.com/m1k2zoo/negbench划重点:🌟 研究人员揭示了视觉语言模型在理解否定方面的不足，主要源于训练数据的偏差。📈 NegBench 框架通过引入丰富的否定示例，显著提升了模型在检索和理解任务上的表现。🔍 微调后的模型在处理否定查询时，准确率和召回率都有显著提高，推动了人工智能系统的进步。
