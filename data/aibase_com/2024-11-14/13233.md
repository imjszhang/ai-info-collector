# ​英伟达Blackwell平台发布：AI训练性能暴增2.2倍，GPU需求大幅减少！

**发布日期**: 2024年11月14号 11:38

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/13233)

## 内容

近日，英伟达发布了其全新的 Blackwell 平台，并在 MLPerf Training4.1基准测试中展示了初步的性能表现。根据测试结果，Blackwell 在某些方面的性能相比于前一代 Hopper 平台实现了翻倍的提升，这一成果引起了业界的广泛关注。在 MLPerf Training4.1基准测试中，Blackwell 平台在 LLM（大语言模型）基准的 Llama270B 微调任务中，每个 GPU 的性能达到了 Hopper 的2.2倍，而在 GPT-3175B 的预训练中则达到了2倍的提升。此外，在 Stable Diffusion v2训练等其他基准测试中，新一代的 Blackwell 也以1.7倍的优势超过了前代产品。值得注意的是，虽然 Hopper 仍在继续展现出进步，但与上一轮 MLPerf Training 基准测试相比，Hopper 在语言模型预训练中的性能也提高了1.3倍。这表明英伟达的技术持续在进步。在最近的 GPT-3175B 基准测试中，英伟达提交了11，616个 Hopper GPU，创下新的扩展记录。关于 Blackwell 的技术细节，英伟达表示，新的架构使用了优化的 Tensor Cores 和更快速的高带宽内存。这使得 GPT-3175B 基准测试的运行仅需64个 GPU，而使用 Hopper 平台则需要256个 GPU 才能实现相同的性能。英伟达在发布会上还强调了 Hopper 代产品在软件和网络更新上的性能提升，预期 Blackwell 也将随着未来的提交持续改进。此外，英伟达计划在明年推出下一代 AI 加速器 Blackwell Ultra，预计将提供更多的内存和更强的计算能力。Blackwell在 MLPerf Inference v4.1基准测试中也于去年九月首次亮相，在 AI 推理方面，它的性能达到了每个 GPU 比 H100多出四倍的惊人成就，尤其是使用了更低的 FP4精度。这一新趋势旨在应对低延迟聊天机器人和像 OpenAI 的 o1模型等智能计算需求的不断增长。划重点:- 🚀 ** 英伟达 Blackwell 平台在 AI 训练中实现性能翻倍，刷新行业标准!**- 📈 ** 在 GPT-3175B 基准测试中，Blackwell 仅需64个 GPU，显著提高了效率!**- 🔍 ** 明年将推出 Blackwell Ultra，预计提供更高的内存和计算能力!**
