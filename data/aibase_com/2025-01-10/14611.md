# ​微软联合清北推rStar-Math技术：小型模型逆袭数学问题，超越 OpenAI！

**发布日期**: 2025年1月10号 9:56

![新闻图片](https://pic.chinaz.com/picmap/thumb/202412271614181718_0.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14611)

## 内容

微软近日宣布了其新的 rStar-Math 技术，这一创新的推理方法可以应用于小型语言模型（SLMs），显著提升它们在数学问题上的表现，甚至在某些情况下超越 OpenAI 的 o1-preview 模型。这一技术目前仍处于研究阶段，相关研究论文已发布在 arXiv.org 上，由微软、北京大学和清华大学的八位作者共同完成。在测试中，rStar-Math 技术被应用于多个小型开源模型，包括微软的 Phi-3迷你模型、阿里巴巴的 Qwen-1.5B（15亿参数模型）和 Qwen-7B(70亿参数模型)。测试结果显示，所有参与的模型性能都有所提升，其中在 MATH 基准测试中，rStar-Math 甚至超越了 OpenAI 先前最先进的模型。研究团队计划在 Github 上开放相关代码和数据，尽管目前仍在内部审核中，尚未公开。社区对此技术表示了极大的兴趣，许多成员称赞其与蒙特卡罗树搜索（MCTS）结合的逐步推理方法，认为这一创新在几何证明和符号推理等领域有着广泛的应用前景。rStar-Math 的核心在于利用蒙特卡罗树搜索，这种方法模拟人类的 “深度思考”，通过逐步细化数学问题的解决方案来帮助小型模型自我演进。研究人员不仅简单地应用了 MCTS，还要求模型在输出过程中同时给出自然语言的推理步骤以及 Python 代码。这样的要求促进了模型的有效训练。在经过四轮自我演进后，rStar-Math 在多个基准测试中取得了显著成就。在 MATH 基准测试中，Qwen2.5-Math-7B 模型的准确率从58.8% 跃升至90.0%，超越了 OpenAI 的 o1-preview。而在美国数学邀请赛（AIME）中，该模型解决了53.3% 的问题，表现位于高中竞争者的前20%。近年来，人工智能创新主要依赖于模型参数的不断增加，然而，随之而来的高昂成本让人们开始质疑这种扩展的可持续性。微软通过 rStar-Math 展示了小型模型的潜力，强调了高效能的方向。这一技术的发布表明，专门的小型模型可以作为大型系统的有力替代方案，为中型组织和学术研究者提供前沿的能力，而无需承担庞大的财务和环境负担。论文入口：https://arxiv.org/pdf/2501.04519划重点:🌟 微软推出 rStar-Math 技术，提升小型模型在数学问题上的表现。📊 该技术已在多种开源模型上测试，部分模型性能超越 OpenAI 的 o1-preview。🔍 研究计划将在 Github 上发布代码，吸引社区关注，展示小型模型的巨大潜力。
