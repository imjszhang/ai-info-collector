# LangChain 研究揭示AI代理在工具使用上面临瓶颈

**发布日期**: 2025年2月12号 16:57

![新闻图片](https://pic.chinaz.com/picmap/202501251530244220_9.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/15306)

## 内容

随着人工智能（AI）技术的不断进步，企业开始探讨是否应该依赖单一的 AI 代理，还是构建一个涵盖更多职能的多代理网络。近日，Orchestration 框架公司 LangChain 进行了相关实验，旨在探讨 AI 代理在面对过多指令和工具时的表现极限。LangChain 在一篇博客中详细介绍了其实验过程，关注的核心问题是:“当一个 ReAct 代理被要求处理过多的指令和工具时，其性能会在何种情况下下降?” 为了回答这一问题，研究团队选择了 ReAct 代理框架，因其被认为是 “最基础的代理架构之一”。图源备注：图片由AI生成，图片授权服务商Midjourney在实验中，LangChain 的目标是评估一名内部邮件助手在两项具体任务中的表现:答复客户问题和安排会议。研究人员使用了一系列预构建的 ReAct 代理，并通过 LangGraph 平台对其进行测试。涉及的语言模型包括 Anthropic 的 Claude3.5Sonnet、Meta 的 Llama-3.3-70B 以及 OpenAI 的多个版本如 GPT-4o 等。实验的第一步是测试邮件助手的客户支持能力，具体来看，代理如何接受客户的邮件并给予回复。接着，LangChain 还特别关注了代理在日历安排上的表现，确保它能够准确记住特定指令。研究人员设定了每个任务30项的压力测试，并将其分为客户支持和日历安排两个领域。结果显示，当给代理过多的任务时，它们常常会感到不堪重负，甚至忘记调用必要的工具。例如，在处理多达七个领域的任务时，GPT-4o 的表现下降至2%。而 Llama-3.3-70B 则在任务测试中失误频频，未能调用发送邮件的工具。LangChain 发现，随着提供上下文的增加，代理的指令执行能力显著下降。尽管 Claude-3.5-sonnet 和其他几种模型在多领域任务中表现相对较好，但在任务复杂性增加时，它们的性能也会逐步下降。公司表示，未来将进一步探讨如何评估多代理架构，以改善代理的性能。
