# ChatGPT 能耗揭秘：每次响应仅需 0.3 瓦，远低于传闻！

**发布日期**: 2025年2月12号 9:08

![新闻图片](https://pic.chinaz.com/picmap/202302112107341554_1.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/15275)

## 内容

最近，一项由非营利组织 Epoch AI 进行的研究揭示了 OpenAI 的聊天机器人平台 ChatGPT 的能耗情况，结果显示，ChatGPT 的能耗远低于早期的估算。根据一些报道，ChatGPT 回答一个问题需要约3瓦时的电力，而 Epoch AI 的研究认为这个数据被高估了。研究表明，使用 OpenAI最新默认模型 GPT-4o 时，平均每个查询仅消耗约0.3瓦时的电力，这一数字甚至低于许多家用电器的能耗。Epoch AI 的数据分析师 Joshua You 表示，传统上人们对 AI 能耗的担忧并没有准确反映出当前的情况。早期的3瓦时估算主要是基于一些过时的研究和假设，当时的假设是 OpenAI 使用的是效率较低的芯片。You 还指出，尽管公众对 AI 未来的能耗有合理的担忧，但对目前的情况并没有清晰的认识。然而，You 也承认，Epoch 的0.3瓦时的数字仍是一个近似值，因为 OpenAI 并未公开详细的能耗计算数据。此外，这项分析也没有考虑到一些附加功能所带来的能耗，比如图像生成或输入处理。对于较长的输入查询，如带有大量文件的查询，You 表示这类查询的能耗可能会更高。尽管目前的能耗数据较低，You 预计未来的能耗仍可能会上升。他提到，随着 AI 技术的进步，训练这些模型的能量需求可能会增加，未来的 AI 也可能承担更复杂的任务，从而消耗更多的电力。与此同时，AI 的基础设施正在快速扩展，这将导致巨大的电力需求。例如，根据 Rand 公司的报告，预计在未来两年内，AI 数据中心可能需要几乎全部加利福尼亚州2022年的电力供应。到2030年，训练一个前沿模型的能耗将达到相当于八个核反应堆的电力输出。OpenAI 和其投资合作伙伴计划在未来几年内在新 AI 数据中心项目上投入数十亿美元。随着 AI 技术的发展，行业的关注也开始转向推理模型，这些模型在处理任务时更具能力，但也需要更多的计算能力和电力支持。对于那些关心自己 AI 能耗的人，You 建议可以减少使用频率，或选择计算需求较低的模型来进行使用。划重点:🌱 ChatGPT 的平均能耗为0.3瓦时，远低于早期估算的3瓦时。🔌 AI 能耗的增加主要与未来的技术进步和更复杂任务的处理有关。🏭 OpenAI 计划在未来几年投入巨额资金扩展 AI 数据中心，以满足日益增长的电力需求。
