# 英伟达发布新视觉语言模型NVILA，击败GPT-4o Mini和Llama 3.2

**发布日期**: 2024年12月9号 8:32

![新闻图片](https://upload.chinaz.com/2024/1209/6386935854954358617445011.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/13789)

## 内容

近日，NVIDIA 推出了新一代开放视觉语言模型 ——NVILA。该旨在优化准确性和效率，凭借出色的性能，成为视觉 AI 领域的佼者。根据 NVIDIA 的介绍，NVILA 在训练成本上降低了4.5倍微调所需内存减少了3.4倍，并且在预填充和解码的延迟上几乎降低了2倍。这些数据是与另一种大型视觉模型 LLaVa OneVision 进行比较得出的。在视频基准测试中，NVILA 的表现超过了 GPT4o Mini，并且在与 GPT4o、Sonnet3.5和 Gemini1.5Pro 的比较中也表现出色。此外，NVILA 还在与 Llama3.2的对比中取得了微弱胜利。尽管如此，NVIDIA 表示，目前尚未将该模型发布到 Hugging Face 平台上，他们承诺会很快发布代码和模型，以促进模型的可复现性。NVIDIA 指出，训练视觉语言模型的成本非常高，训练一个7B 参数的视觉语言模型大约需要400个 GPU 天。同时，微调这样的模型也非常耗费内存，7B 参数的模型需要超过64GB 的 GPU 内存。因此，NVIDIA 采用了一种名为 “先扩展后压缩” 的技术，旨在平衡模型的准确性与效率。该模型并不通过降低照片和视频的大小来化输入，而是使用高分辨率像和视频中的多个帧，以确保不丢失任何细节。在压缩过程中，模型通过将视觉信息压缩为更少的 token，来减少输入数据的大小，并将像素进行分组，以保留重要信息。NVIDIA 在论文中提到，双倍分辨率将使视觉 token 数量翻倍，这将使训练和推理成本增加超过2倍。因此，他们通过压缩空间 / 时间 token 降低这部分成本。NVIDIA 还展示些模型的演示效果，NVILA 能够根据一张图片或一段视频回答多个查询。它的输出结果还与 NVIDIA 之前发布的 VILA1.5模型进行了对比。此外，NVIDIA 还详细介绍了一些其他技术，例如动态 S2扩展、基于 DeltaLoss 的数据集修剪、使用 FP8精度进行量化等。这些技术均应用于一个8B 参数的模型，具体细节可以在 Arxiv 上查看。论文入口:https://arxiv.org/pdf/2412.04468划重点:🌟 NVILA 模型在训练成本上降低了4.5倍，提升了视觉 AI 的效率。📉 通过高分辨率图像和视频帧，NVILA 确保了输入信息的完整性。📊 NVIDIA 承诺将很快发布代码与模型，促进研究的可复现性。
