# ​Hugging Face推2B参数视觉语言模型SmolVLM：在普通设备就能飞速运行

**发布日期**: 2024年11月27号 15:56

![新闻图片](https://upload.chinaz.com/2024/1127/6386831971005427205121197.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/13528)

## 内容

近年来，机器学习模型在视觉和语言任务方面的应用需求日益增长，但大多数模型都需要庞大的计算资源，无法在个人设备上高效运行。尤其是像笔记本电脑、消费级 GPU 和移动设备等小型设备，在处理视觉语言任务时面临巨大的挑战。以 Qwen2-VL 为例，虽然其性能卓越，但对硬件的要求较高，限制了其在实时应用中的可用性。因此，开发出轻量化模型以便于在较低资源下运行，成为了一项重要需求。Hugging Face 近期发布了 SmolVLM，这是一款专门为设备端推理设计的2B 参数视觉语言模型。SmolVLM 在 GPU 内存使用和令牌生成速度方面的表现超越了其他同类模型。其主要特性是能够在较小的设备上有效运行，比如笔记本电脑或消费级 GPU，而不会牺牲性能。SmolVLM 在性能和效率之间找到了一个理想的平衡，解决了以往同类模型难以克服的问题。与 Qwen2-VL2B 相比，SmolVLM 生成令牌的速度快了7.5到16倍，归功于其优化的架构，使得轻量级推理成为可能。这一效率不仅为最终用户带来了实用的好处，也极大提升了使用体验。从技术角度来看，SmolVLM 具有优化的架构，支持高效的设备端推理。用户甚至可以在 Google Colab 上轻松进行微调，极大地降低了试验和开发的门槛。由于内存占用小，SmolVLM 能够在之前无法承载同类模型的设备上顺利运行。在对50帧 YouTube 视频进行测试时，SmolVLM 表现出色，得分达到27.14%，并在资源消耗上优于两款更为消耗资源的模型，显示了其强大的适应能力和灵活性。SmolVLM 在视觉语言模型领域具有重要的里程碑意义。它的推出使得复杂的视觉语言任务能够在日常设备上运行，填补了当前 AI 工具中的一项重要空白。SmolVLM 不仅在速度和效率方面表现优异，还为开发者和研究者提供了一个强大的工具，以便于进行视觉语言处理，而无需投入高昂的硬件费用。随着 AI 技术的不断普及，像 SmolVLM 这样的模型将使得强大的机器学习能力变得更加触手可及。demo:https://huggingface.co/spaces/HuggingFaceTB/SmolVLMhttps://huggingface.co/spaces/HuggingFaceTB/SmolVLM划重点:🌟 SmolVLM 是 Hugging Face 推出的专为设备端推理设计的2B 参数视觉语言模型，运行高效且无需高端硬件。⚡ 它的令牌生成速度是同类模型的7.5到16倍，极大提高了用户的体验和应用效率。📊 在测试中，SmolVLM 展现了强大的适应能力，在没有视频数据训练的情况下仍能取得不错的评分。
