# 苹果与NVIDIA联手提升AI模型生产效率，速度提升近三倍

**发布日期**: 2024年12月20号 3:26

![新闻图片](https://upload.chinaz.com/2024/1220/6387029064841550593501436.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14142)

## 内容

近日，苹果公司在机器学习领域的最新研究显示，他们通过与 NVIDIA 的合作，成功将大型语言模型（LLM）的生成速度提高了近三倍。这一进展的关键在于苹果开源的技术 “Recurrent Drafter”(ReDrafter)，它采用了一种推测解码方法，能够显著提升模型训练的效率。在过去，创建大型语言模型的过程通常非常耗时和耗资源，企业常常需要购买大量的硬件设备，进而增加了运营成本。2024年早些时候，苹果发布了 ReDrafter，这一技术结合了递归神经网络和动态树关注的方法，能够快速生成和验证标记，较传统的自动回归方法提升了3.5倍的标记生成速度。本周，苹果进一步宣布，他们与 NVIDIA 的合作将 ReDrafter 整合进 NVIDIA 的 TensorRT-LLM 推理加速框架。此举将使得使用 NVIDIA GPU 的机器学习开发者能够在生产环境中利用 ReDrafter 的加速功能。值得一提的是，虽然高性能的多 GPU 服务器通常价格昂贵，但此次合作能够在降低延迟的同时减少所需硬件数量，带来更为经济的解决方案。在与 NVIDIA 进行的基准测试中，使用 ReDrafter 的生成效率得到了显著提升，贪婪编码模式下的每秒生成令牌速度提高了2.7倍。这意味着开发者们可以在更短的时间内得到更多的结果，为用户提供更快的服务体验。苹果公司在确认与 NVIDIA 的合作后，也表示他们正在考虑使用亚马逊的 Trainium2芯片来提升模型训练效率。预计使用 Trainium2进行预训练的效率将比现有的硬件提升50%。官方博客:https://developer.nvidia.com/blog/nvidia-tensorrt-llm-now-supports-recurrent-drafting-for-optimizing-llm-inference/划重点:🌟 苹果与 NVIDIA 合作，将大型语言模型的生成速度提升近三倍。🚀 开源技术 ReDrafter 结合递归神经网络，显著提高模型训练效率。💰 此次合作有助于降低成本，为机器学习开发者提供更高效的解决方案。
