# 尴尬！谷歌被曝用Claude模型进行对比测试 来改进Gemini AI

**发布日期**: 2024年12月25号 2:19

![新闻图片](https://pic.chinaz.com/picmap/thumb/202311281038503909_6.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14235)

## 内容

近日，谷歌的 Gemini 人工智能项目正在通过比较其输出结果与 Anthropic 公司的 Claude 模型来提升自身性能。据 TechCrunch 获得的内部通信记录显示，负责 Gemini 改进的承包商正在系统地评估这两种 AI 模型的回答。图源备注：图片由AI生成，图片授权服务商Midjourney在 AI 行业，模型的性能评估通常通过行业基准测试来进行，而不是让承包商逐一对比不同模型的答案。负责 Gemini 的承包商需要根据多个标准对模型的输出进行评分，包括真实性和详细程度。他们每次有多达30分钟的时间来判断 Gemini 和 Claude 的回答哪个更好。最近，这些承包商注意到在他们使用的内部平台上，Claude 的引用频繁出现。部分显示给承包商的内容明确表示:“我是由 Anthropic 创建的 Claude。” 在一次内部聊天中，承包商们还发现 Claude 的回答在强调安全性方面表现得更加突出。有承包商指出，Claude 的安全设置在所有 AI 模型中是最严格的。在某些情况下，Claude 会对它认为不安全的提示选择不回应，比如角色扮演其他 AI 助手。而在另一个案例中，Claude 回避了某个提示，而 Gemini 的回答却因包含 “裸露和绑缚” 内容而被标记为 “重大安全违规”。需要注意的是，Anthropic 的商业服务条款禁止客户在未获得授权的情况下使用 Claude “构建竞争产品或服务” 或 “训练竞争 AI 模型”。谷歌则是 Anthropic 的主要投资者之一。谷歌 DeepMind 的发言人 Shira McNamara 在接受 TechCrunch 采访时未透露谷歌是否获得了 Anthropic 的批准来使用 Claude。McNamara 表示，DeepMind 确实会比较模型输出进行评估，但并未对 Gemini 进行 Claude 模型的训练。她提到:“当然，按照行业标准做法，我们在某些情况下会将模型输出进行比较。然而，任何关于我们使用 Anthropic 模型训练 Gemini 的说法都是不准确的。”上周，TechCrunch 还独家报道，谷歌的承包商被要求在自己专业领域以外的领域对 Gemini 的 AI 响应进行评分。一些承包商在内部通信中表示担忧，认为 Gemini 可能在敏感主题如医疗保健上生成不准确的信息。划重点:🌟 Gemini 正在与 Claude 进行对比测试，以提升自身 AI 模型的性能。🔍 承包商负责评分，两者的回答比较涉及多个标准，包括真实性和安全性。🚫 Anthropic 禁止在未授权的情况下使用 Claude 进行竞争性模型的训练。
