# 重磅！AI科学家另辟蹊径，用大模型竟能自动探索人工生命

**发布日期**: 2024年12月25号 6:18

![新闻图片](https://pic.chinaz.com/picmap/thumb/202307181533376338_16.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14246)

## 内容

近日，Sakana AI 的科学家们在人工智能领域取得了突破性进展，他们首次成功利用视觉语言基础模型（vision-language foundation models，FMs） 实现了人工生命(Artificial Life，ALife) 模拟的自动搜索。这项名为 ASAL(Automated Search for Artificial Life，人工生命自动搜索) 的新方法，为人工生命领域的研究带来了革命性的变革，有望加速该领域的发展。传统的人工生命研究主要依赖人工设计和试错，而 ASAL 的出现改变了这一现状。该方法的核心是通过基础模型来评估模拟产生的视频，从而自动搜索有趣的 ALife 模拟。ASAL 主要通过三种机制来发现生命形式:有监督的目标搜索:通过文本提示来寻找产生特定现象的模拟。例如，研究人员可以设定“一个细胞”或“两个细胞”这样的目标，让系统自动找出符合条件的模拟。  开放性搜索:寻找能产生时间上无休止的新颖性的模拟。这种方式有助于发现那些对人类观察者来说持续有趣的模拟。启发式搜索:寻找一组有趣且多样的模拟，从而揭示 “外星世界”。ASAL 的通用性使其能够有效地应用于多种 ALife 基质，包括 Boids、粒子生命（Particle Life）、生命游戏(Game of Life)、Lenia 和神经元胞自动机(Neural Cellular Automata)。研究人员在这些基质中发现了前所未见的生命形式，例如，Boids 中出现了奇异的群集模式，Lenia 中出现了新的自组织细胞，以及类似康威生命游戏的开放式细胞自动机。此外，ASAL 还支持对以往只能进行定性分析的现象进行定量分析。基础模型具有与人类相似的表示能力，这使得 ASAL 能够以一种更符合人类认知的方式来衡量复杂性。例如，研究人员可以通过测量 CLIP 向量在模拟过程中的变化速度来量化 Lenia 模拟中的平台期。该研究的创新之处在于 利用了预训练的基础模型，特别是 CLIP（对比语言-图像预训练） 模型，来评估模拟的视频。CLIP 模型通过对比学习，将图像和文本的表示对齐，使其能够理解人类对复杂性的概念。ASAL 的方法并不局限于特定的基础模型或模拟基质，这意味着它可以与未来的模型和基质兼容。研究人员还通过实验验证了 ASAL 的有效性，他们使用不同的基础模型（如 CLIP 和 DINOv2）以及不同的 ALife 基质进行测试。结果表明，CLIP 在生成符合人类认知的多样性方面略优于 DINOv2，但两者都明显优于低级别的像素表示。这突显了使用深度基础模型表示来衡量人类多样性概念的重要性。这项研究为人工生命领域开辟了新的道路，使得研究人员能够将精力集中于更高层次的问题，例如，如何最好地描述我们希望出现的现象，然后让自动化的过程去寻找这些结果。ASAL 的出现，不仅能够帮助科学家发现新的生命形式，而且能够定量分析生命模拟中的复杂性和开放性。最终，这项技术有望帮助人们理解生命的本质，以及生命在宇宙中可能存在的所有形式。项目代码:https://github.com/SakanaAI/asal/论文地址:https://arxiv.org/pdf/2412.17799
