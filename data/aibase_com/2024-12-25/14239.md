# 研究发现，OpenAI 的 o1-preview 在诊断复杂医疗病例方面优于医生

**发布日期**: 2024年12月25号 2:40

![新闻图片](https://pic.chinaz.com/picmap/thumb/202307181418301728_3.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14239)

## 内容

一项新研究表明，OpenAI 的 o1-preview 人工智能系统在诊断复杂医疗案例方面，可能优于人类医生。哈佛医学院和斯坦福大学的研究团队对 o1-preview 进行了全面的医疗诊断测试，结果显示该系统相比于早期版本有了显著进步。根据研究结果，o1-preview 在所有被测试的病例中，正确诊断率达到了78.3%。在对70个特定病例的直接比较中，该系统的准确诊断率更是达到了88.6%，显著超越了其前身 GPT-4的72.9%。在医疗推理方面，o1-preview 的表现同样引人注目。使用 R-IDEA 量表这一医疗推理质量评估标准，该 AI 系统在80个病例中获得了78个满分。相较之下，经验丰富的医生仅在28个病例中获得满分，而医学住院医师则仅在16个病例中达到满分。研究人员也承认，o1-preview 在训练数据中可能包含了一些测试案例。然而，当他们对系统进行新案例的测试时，性能只略有下降。研究作者之一亚当・罗德曼博士强调，虽然这是一项基准研究，但研究结果对医疗实践有重要的启示。o1-preview 在处理由25名专家特别设计的复杂管理案例时表现尤为突出。“人类在这些难题面前显得力不从心，但 o1的表现让人惊艳，” 罗德曼解释道。在这些复杂案例中，o1-preview 获得了86% 的得分，而医生使用 GPT-4仅获得41%，传统工具更是只有34%。不过，o1-preview 并非毫无缺陷。在概率评估方面，该系统的表现没有明显改善，比如在评估肺炎的可能性时，o1-preview 给出了70% 的估计，这远高于科学范围25%-42%。研究人员发现，o1-preview 在需要批判性思维的任务上表现优异，但在更抽象的挑战中，如估计概率方面则显得力不从心。此外，o1-preview 通常提供详细的答案，这可能提升了其评分。但研究仅关注 o1-preview 单独工作的情况，而没有评估其与医生合作的效果。一些批评者指出，o1-preview 建议的诊断测试往往成本高昂且不切实际。尽管 OpenAI 已发布了全新版本的 o1和 o3，并在复杂推理任务中表现出色，但这些更强大的模型仍未能解决批评者提出的实际应用和成本问题。罗德曼呼吁，研究人员需要更好的评估医疗 AI 系统的方法，以便在现实医疗决策中捕捉复杂性。他强调，这项研究并不意味着可以取代医生，实际医疗仍需要人类的参与。论文:https://arxiv.org/abs/2412.10849划重点:🌟 o1-preview 在诊断率上超过医生，达到88.6% 的准确率。🧠 医疗推理方面，o1-preview 在80个病例中获得78个满分，远超医生表现。💰 尽管表现优秀，o1-preview 在实际应用中的高成本和不切实际的测试建议仍需解决。
