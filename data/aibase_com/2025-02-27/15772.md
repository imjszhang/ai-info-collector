# 阿里开源视频生成模型Wan 2.1上线即屠榜 4070可流畅运行

**发布日期**: 2025年2月27号 10:08

![新闻图片](https://pic.chinaz.com/picmap/202405161743122232_2.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/15772)

## 内容

近日，阿里巴巴在深夜推出了全新的开源视频生成模型 Wan2.1，该模型凭借14B 的参数量迅速占据了 VBench 榜单的顶端，成为目前视频生成领域的佼佼者。与此之前发布的 QwQ-Max 不同，Wan2.1在复杂运动的细节处理上表现出色，能够流畅地实现多个人物的同步舞蹈，令人惊叹不已。官方演示中，Wan2.1不仅成功克服了静态图像生成中的难题，如文字的处理更是达到了新的高度。对于普通用户来说，虽然14B 的参数在个人消费级显卡上部署较为困难，但阿里还特别推出了一个1.3B 的小版本，支持480P 分辨率，使用12GB 显存的4070显卡即可流畅运行。图源备注：图片由AI生成，图片授权服务商Midjourney除了14B 和1.3B 版本，阿里还发布了两个额外的视频生成模型，均采用 Apache2.0协议，意味着用户可以免费商用。在实际操作中，用户可以通过阿里提供的平台访问这款模型，快速生成视频，但由于用户量激增，有时可能会出现等待时间过长的情况。对于有一定技术基础的用户，还可以通过 HuggingFace 和魔搭社区等多种途径自行安装和调试。Wan2.1最大的亮点在于其技术创新。该模型采用了 Diffusion Transformer 架构，并使用3D 变分自动编码器，专门为视频生成设计。通过引入多种压缩和并行策略，该模型在保证质量的同时，大幅度提高了生成效率。研究表明，Wan 的重建速度是当前同类技术的2.5倍，大大节省了计算资源。在用户体验方面，Wan2.1也获得了众多好评。无论是生成动态场景中的细节，还是自然的物理效果，模型的表现都让人眼前一亮。用户们通过该模型不仅能够制作出高质量的视频作品，还能轻松实现文字的动态呈现，为创作带来了更多可能。阿里巴巴的 Wan2.1模型不仅技术先进，而且为广大创作者提供了更多的创作自由度，标志着视频生成技术的又一突破。
