# 微软发布 Phi-4 多模态与迷你模型，语音视觉文本处理再升级

**发布日期**: 2025年2月27号 9:38

![新闻图片](https://pic.chinaz.com/picmap/thumb/202307211343352678_2.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/15766)

## 内容

近日，微软进一步扩展了 Phi-4家族，推出了两款新模型:Phi-4多模态（Phi-4-multimodal）和 Phi-4迷你(Phi-4-mini)，这两款模型的亮相，无疑将为各类 AI 应用提供更加强大的处理能力。Phi-4多模态模型是微软首款集成语音、视觉和文本处理的统一架构模型，拥有5600万参数。这款模型在多项基准测试中表现优异，超越了目前市场上的许多竞争对手，例如谷歌的 Gemini2.0系列。在自动语音识别（ASR）和语音翻译(ST)任务中，Phi-4多模态模型表现尤为突出，成功击败了如 WhisperV3和 SeamlessM4T-v2-Large 等专业语音模型，词错误率更是以6.14% 的成绩位居 Hugging Face OpenASR 排行榜首位。在视觉处理方面，Phi-4多模态模型同样表现出色。其在数学和科学推理方面的能力令人印象深刻，能够有效理解文档、图表和执行光学字符识别（OCR）。与 Gemini-2-Flash-lite-preview 和 Claude-3.5-Sonnet 等流行模型相比，该模型的表现不相上下，甚至更胜一筹。另一款新发布的 Phi-4迷你模型则专注于文本处理任务，参数量为3800万。在文本推理、数学计算、编程和指令遵循等方面，Phi-4迷你表现卓越，超越了多款流行的大型语言模型。为了确保新模型的安全性和可靠性，微软邀请了内部与外部的安全专家进行全面测试，并按照微软人工智能红队（AIRT）的标准进行优化。这两款新模型均可通过 ONNX Runtime 部署到不同设备上，适用于多种低成本和低延迟的应用场景。它们已在 Azure AI Foundry、Hugging Face 和 NVIDIA API 目录中上线，供开发者使用。毫无疑问，Phi-4系列的新模型标志着微软在高效 AI 技术上的重大进步，为未来的人工智能应用打开了新的可能性。
