# ​AI2推出开源 Tülu3模型，性能与GPT-4o mini相当

**发布日期**: 2024年12月10号 7:51

![新闻图片](https://pic.chinaz.com/picmap/thumb/202306271716249909_0.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/13830)

## 内容

在人工智能领域，后训练技术正逐渐成为提升模型性能的重要手段。近日，艾伦人工智能研究所（AI2）发布了 Tülu3系列模型，这是一套完全开源的先进语言模型，性能与 GPT-4o-mini 等闭源相媲美。Tülu3不仅包含了模型数据、代码、训练配方，还提供了评估框架，旨在推动开源模型后训练技术的发展。传统上，仅经过预训练的模型往往无法有效满足实际应用需求，可能会产生有毒或危险的信息，且难以遵循人类指令。因此，后训练阶段如指令微调和人类反馈学习显得尤为重要。然而，如何优化后训练过程仍然是一个技术难题，尤其是在提升模型某一能力的同时，可能会影响到其他能力。为了攻克这一难题，各大公司纷纷提升了后训练方法的复杂性，尝试多轮训练和结合人工与合成数据，但大部分方法仍为闭源。与之形成对比的是，Tülu3系列的发布，突破了开源模型和闭源模型之间的性能差距，带来了全新的训练思路。Tülu3的训练过程分为四个阶段:数据构造、监督微调、偏好调整和可验证奖励的强化学习。首先，研究人员聚焦于模型的核心技能，通过人工数据与合成数据的结合来构建训练数据。其次，进行监督式微调，以确保模型在特定技能上的表现不逊色于其他先进模型。第三，采用直接偏好优化的方法来进一步提升模型的整体表现。最后，创新引入可验证奖励强化学习的方法，帮助模型更好地完成可验证结果的任务。Tülu3模型基于 Llama3.1的基础上进行构建，在推理、数学、编程和指令遵循等领域表现优异。与其他开源和闭源模型相比，Tülu3的综合能力在多个基准测试中表现出色，标志着开源后训练技术的一次重大进步。论文链接:https://allenai.org/papers/tulu-3-report.pdfDemo:https://playground.allenai.org/划重点:🌟 Tülu3是 AI2推出的开源语言模型，与闭源模型如 GPT-4o-mini 性能相当。🔧 后训练技术至关重要，能够有效提升模型在实际应用中的表现。📊 Tülu3的训练过程创新，分为数据构造、监督微调、偏好调整和可验证奖励强化学习四个阶段。
