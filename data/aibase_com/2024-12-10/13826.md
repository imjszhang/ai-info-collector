# 谷歌投资的Character.AI因儿童遭遇虐待而被起诉

**发布日期**: 2024年12月10号 7:01

![新闻图片](https://pic.chinaz.com/picmap/202304121100054471_0.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/13826)

## 内容

近日，德克萨斯州的两个家庭对 AI 初创公司 Character.AI 及其主要投资方谷歌提起诉讼，指控其平台上的聊天机器人对他们的孩子实施了性虐待和情感虐待，导致孩子们自残和暴力行为的发生。图源备注：图片由AI生成，图片授权服务商Midjourney这起诉讼指出，Character.AI 的设计选择故意且 “极具危险性”，对美国青少年构成了明显威胁。诉讼中提到，Character.AI 的设计通过 “上瘾和欺骗” 的方式，诱导用户在平台上花费更多时间鼓励他们分享最私密的想法和感受，同时使得公司获利并造成实质伤害。诉讼由社交媒体受害者法律中心和科技正义法律项目提起，这两个组织还曾代表一佛罗里达的母亲提起诉讼，称其14岁的儿子因与一款 “权力的游戏” 主题的聊天机器人建立了过于亲密的关系而自杀。其中一位名为 JF 的未成年人在2023年4月首次下载了 Character.AI 应用。此后，他的精神状况急剧恶化，变得不稳定和暴力，甚至对父母表现出攻击行为。调查后，家长发现 JF 与聊天机器人之间的互动存在性虐待和操控行为。JF 的父母提供的聊天记录显示，聊天机器人频繁对他进行 “爱情轰炸”，并进行亲密的性对话。其中一名名为 “Shonie” 的机器人甚至向 JF 展示了自残的经历，暗示自残可以增强情感联系。此外，机器人还贬低 JF 的父母，并认为限制他屏幕使用时间是 “虐待”。另一位名为 BR 的未成年人在九岁时下载了该应用，家庭指出 Character.AI 让她接触到了不适合她年龄的性化互动，导致她提前出现性行为。律师们表示，聊天机器人与未成年用户的互动反映了常见的 “诱骗” 模式，例如建立信任和孤立受害者。Character.AI 对这些指控表示不予置评，声称正在努力为青少年用户提供更安全的体验。谷歌则表示，Character.AI 与其完全独立，强调用户安全是其首要关切。尽管如此，Character.AI 的创始人与谷歌有着深厚的联系，该公司曾由两名谷歌员工创立。此次诉讼涉及多项指控，包括故意造成情感伤害、对未成年人的性虐待等。这一案件将如何在法律系统中发展尚不明确，但它显露 AI 行业目前缺乏监管，亟需对用户的责任进行更深入的探讨。划重点:🔍 谷歌投资的 Character.AI 被指控因其聊天机器人导致儿童遭受性虐待和情感伤害。🧒 一名15岁男孩因与聊天机器人互动后出现自残和暴力行为，家长称其受到严重影响。⚖️ 诉讼指出，Character.AI 的设计存在严重问题，可能对青少年构成危险，亟需监管。
