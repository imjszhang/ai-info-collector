# DisPose：输入动作视频和参考人物即可实现让人物跳同款舞蹈

**发布日期**: 2024年12月24号 9:50

![新闻图片](https://pic.chinaz.com/thumb/2024/1224/24122409494969793284.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14205)

## 内容

近年来，随着人工智能和计算机视觉技术的迅猛发展，人与计算机之间的交互变得越来越生动和富有表现力。尤其是在动画制作领域，如何实现基于静态图像生成动态视频一直是研究的热点。近日，一项名为 “DisPose” 的新技术应运而生，它通过解耦姿态指导，实现了更加可控的人物图像动画效果。简单的说，DisPose实现了输入动作视频和参考人物，可以让参考人物实现视频里的动作。DisPose 技术的核心在于其对传统稀疏姿态信息的重构与利用。传统方法多依赖于稀疏的骨骼姿态指导，这在动态生成视频时往往无法提供足够的控制信号，导致动画效果不够精细。为了弥补这一不足，DisPose 提出了一种全新的方法，通过将稀疏的姿态信息转化为运动场指导和关键点对应关系，实现了更加细致的运动生成。具体来说，DisPose 首先通过对骨骼姿态计算稀疏运动场，并基于参考图像引入了一种密集运动场的生成方式。这一方式不仅提供了区域级别的运动信号，还保持了稀疏姿态控制的普遍性。同时，DisPose 还从参考图像中提取与姿态关键点相对应的扩散特征，然后通过计算多尺度的点对应关系，将这些特征传递到目标姿态，以增强外观的一致性。为了使这一创新技术能够顺利融入现有模型中，研究人员还提出了一种插件式的混合 ControlNet 架构。这一架构在不改变现有模型参数的基础上，提高了生成视频的质量和一致性。通过广泛的定性和定量实验，DisPose 展现出相较于当前技术的显著优势，预示着动画制作技术的未来发展方向。DisPose 通过优化姿态信息的利用方式，提升了人像动画的表现力与控制性。这一进展不仅在学术研究上具有重要意义，也为未来的动画产业带来了新的可能性。项目入口：https://lihxxx.github.io/DisPose/划重点:📍 DisPose 是一种新的人像动画技术，通过解耦姿态指导实现更精确的动态生成。🎨 该技术将稀疏姿态信息转化为运动场指导和关键点对应，提供细致的运动信号。🔧 研究者提出的混合 ControlNet 架构能有效提高生成视频的质量和一致性。
