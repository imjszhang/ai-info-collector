# LLM为啥总是被数学题难倒？AI算术推理竟是靠“蒙”的！

**发布日期**: 2024年11月19号 16:58

![新闻图片](https://pic.chinaz.com/picmap/thumb/202310270933175014_5.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/13330)

## 内容

最近，AI 大型语言模型（LLM）在各种任务中表现出色，写诗、写代码、聊天都不在话下，简直是无所不能!但是，你敢相信吗?这些“天才”AI 居然是“数学菜鸟”!它们在处理简单的算术题时经常翻车，让人大跌眼镜。一项最新的研究揭开了 LLM 算术推理能力背后的“奇葩”秘诀:它们既不依赖强大的算法，也不完全依靠记忆，而是采用了一种被称为“启发式大杂烩”的策略! 这就好比一个学生，没有认真学习数学公式和定理，而是靠着一些“小聪明”和“经验法则”来蒙答案。研究人员以算术推理作为典型任务，对 Llama3、Pythia 和 GPT-J 等多个 LLM 进行了深入分析。他们发现，LLM 模型中负责算术计算的部分（称为“电路”）是由许多单个神经元组成的，每个神经元都像一个“微型计算器”，只负责识别特定的数字模式并输出对应的答案。 比如，一个神经元可能专门负责识别“个位数是8的数字”，另一个神经元则负责识别“结果在150到180之间的减法运算”。这些“微型计算器”就像一堆杂乱无章的工具，LLM 并非按照特定的算法来使用它们，而是根据输入的数字模式，随机地组合使用这些“工具”来计算答案。 这就像一个厨师，没有固定的菜谱，而是根据手边现有的食材，随意搭配，最终做出一道“黑暗料理”。更令人惊讶的是，这种“启发式大杂烩”的策略居然在 LLM 训练的早期就出现了，并随着训练的进行逐渐完善。这意味着，LLM 从一开始就依赖于这种“拼凑”式的推理方法，而不是在后期才发展出这种策略。那么，这种“奇葩”的算术推理方法会导致什么问题呢?研究人员发现，“启发式大杂烩”策略的泛化能力有限，容易出现错误。 这是因为 LLM 所掌握的“小聪明”数量有限，而且这些“小聪明”本身也可能存在缺陷，导致它们在遇到新的数字模式时无法给出正确答案。 就像一个只会做“番茄炒蛋”的厨师，突然让他做一道“鱼香肉丝”，他肯定会手忙脚乱，不知所措。这项研究揭示了 LLM 算术推理能力的局限性，也为未来改进 LLM 的数学能力指明了方向。 研究人员认为，仅仅依靠现有的训练方法和模型架构可能不足以提升 LLM 的算术推理能力，需要探索新的方法来帮助 LLM 学习更强大、更泛化的算法，让它们真正成为“数学高手”。论文地址：https://arxiv.org/pdf/2410.21272
