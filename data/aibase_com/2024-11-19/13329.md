# 英国AI诈骗激增30%！名人声音被克隆恶意利用引发警惕

**发布日期**: 2024年11月19号 16:32

![新闻图片](https://pic.chinaz.com/picmap/202308111005430160_0.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/13329)

## 内容

随着人工智能技术的不断进步，声音克隆技术逐渐走入公众视野，然而其潜在的风险也随之显现。最近，多位知名人士的声音被不法分子恶意克隆，成为诈骗的工具。包括著名自然纪录片主持人大卫・阿滕伯勒在内的多位名人，纷纷对此表示担忧，并呼吁加强法律保护。图源备注:图片由AI生成，图片授权服务商Midjourney近期，大卫・阿滕伯勒在发现自己的声音被用于传播政治新闻后，感到 “深感不安”。他表示，自己一生致力于传播真相，现在却发现身份被他人盗用，这种情况让他感到愤怒与失望。此外，詹妮弗・安妮斯顿、奥普拉・温弗瑞和凯莉・詹纳等明星的声音也遭到不法分子的克隆，表明这一现象的普遍性。根据最新的调查，英国的 AI 声音克隆诈骗案件在过去一年中增加了30%。调查显示，约28% 的人在过去一年中至少遇到过一次 AI 声音克隆的诈骗。这些诈骗往往以模糊的电话和仿冒的声音为背景，使得受害者难以分辨真伪。专家建议，接到可疑电话时，最好立即挂断并拨打可信的电话号码进行确认。随着声音克隆技术的不断提升，专家们开始关注这项技术所带来的法律挑战。多米尼克・李斯博士表示，目前的隐私和版权法律尚未适应这一新技术的发展，导致许多受害者如阿滕伯勒几乎无能为力。他正在为英国议会文化、媒体和体育委员会提供咨询，研究如何在影视制作中道德使用 AI 技术。不仅如此，李斯还指出，尽管 AI 在声音合成方面取得了显著进展，但它依然无法完全理解情感变化，从而影响声音的真实感。此外，配音行业也在快速响应这一变化，部分公司开始克隆一些艺术家的声音，以便满足市场需求。总的来说，声音克隆技术的兴起引发了广泛的关注，尤其是在保护个人隐私和声誉方面。专家们呼吁政府尽快采取措施，以应对 AI 技术带来的新挑战，避免让这一技术成为犯罪分子的工具。划重点:🎙️ 名人声音被恶意克隆，阿滕伯勒等人表示深感不安。📈 英国 AI 声音克隆诈骗案件增加30%，公众警惕性提升。⚖️ 专家呼吁更新法律，以应对 AI 技术对隐私和版权的挑战。
