# 谷歌Gemini 2.0版正式发布：2.0 Flash现已支持多模态输出

**发布日期**: 2024年12月12号 0:19

![新闻图片](https://upload.chinaz.com/2024/1212/6386958822715045004026946.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/13879)

## 内容

谷歌公司及其母公司Alphabet的首席执行官桑达尔·皮查伊宣布，公司推出了最新人工智能模型——Gemini2.0，这标志着谷歌在构建通用AI助理领域迈出了重要一步。Gemini2.0在多模态输入处理和原生工具使用方面展现了显著进步，使得AI代理能够更深入地理解周围世界，并在用户监督下代表用户采取行动。Gemini2.0基于其前身Gemini1.0和1.5开发，后者首次实现了原生多模态处理能力，能够理解包括文本、视频、图像、音频和代码在内的多种信息类型。目前，已有数百万开发者使用Gemini进行开发，推动谷歌重新构想其产品，包括服务20亿用户的7款产品，并创造新产品。NotebookLM便是多模态和长上下文能力的一个例证，受到了广泛喜爱。Gemini2.0的推出预示着谷歌进入了一个新的代理时代，该模型具备原生图像和音频输出能力，以及原生工具使用能力。谷歌已经开始将Gemini2.0提供给开发者和受信任的测试者，并计划快速将其整合到产品中，首先是Gemini和搜索。从即日起，Gemini2.0Flash实验模型将向所有Gemini用户开放。同时，谷歌还推出了名为Deep Research的新功能，它使用先进的推理和长上下文能力，充当研究助理，代表用户探索复杂主题并编制报告。该功能目前已在Gemini Advanced中提供。搜索作为受AI影响最大的产品之一，谷歌的AI概览现已覆盖10亿人，使他们能够提出全新的问题，迅速成为谷歌最受欢迎的搜索功能之一。作为下一步，谷歌将把Gemini2.0的先进推理能力带入AI概览，以解决更复杂的主题和多步骤问题，包括高级数学方程、多模态查询和编码。本周已开始限量测试，并计划在明年初更广泛地推出。谷歌还将继续在未来一年将AI概览带到更多国家和语言。谷歌还通过Gemini2.0的原生多模态能力展示了其代理研究的前沿成果。Gemini2.0Flash在1.5Flash的基础上进行了改进，1.5Flash是迄今为止最受开发者欢迎的模型，具有类似的快速响应时间。值得注意的是，2.0Flash甚至在关键基准测试中以两倍的速度超越了1.5Pro。2.0Flash还带来了新的能力。除了支持图像、视频和音频等多模态输入外，2.0Flash现在还支持多模态输出，如与文本混合的原生生成图像和可控制的多语言文本转语音（TTS）音频。它还可以原生调用工具，如谷歌搜索、代码执行以及第三方用户定义函数。Gemini2.0Flash现在作为实验模型向开发者提供，通过谷歌AI Studio和Vertex AI的Gemini API，所有开发者都可以使用多模态输入和文本输出，而文本转语音和原生图像生成则提供给早期访问合作伙伴。普通可用性将在1月份跟进，同时还会推出更多模型尺寸。为了帮助开发者构建动态和交互式应用，谷歌还发布了一个新的多模态实时API，该API具有实时音频、视频流输入能力，并能够使用多个组合工具。从今天开始，全球的Gemini用户可以通过在桌面和移动网页上的模型下拉菜单中选择它来访问2.0Flash实验的聊天优化版本，它将很快在Gemini移动应用中提供。明年初，谷歌将把Gemini2.0扩展到更多的谷歌产品。
