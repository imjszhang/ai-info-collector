# Hugging Face 推出小巧AI模型，助力设备性能提升

**发布日期**: 2025年1月24号 10:13

![新闻图片](https://pic.chinaz.com/picmap/thumb/202307211343352678_2.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14978)

## 内容

近期，人工智能开发平台 Hugging Face 团队发布了两款新型 AI 模型，SmolVLM-256M 和 SmolVLM-500M。他们自信地声称，这两款模型是目前为止体积最小的 AI 模型，能够同时处理图像、短视频和文本数据，尤其适合内存少于1GB 的设备如笔记本电脑。这一创新让开发者在处理大量数据时，能够以更低的成本实现更高的效率。这两款模型的参数分别为256百万和500百万，这意味着它们在解决问题的能力上也相应有所提升，参数越多，模型的表现通常越好。SmolVLM 系列能够执行的任务包括对图像或视频片段进行描述，以及回答关于 PDF 文档及其内容的问题，比如扫描文本和图表。这使得它们在教育、研究等多个领域具备了广泛的应用前景。在模型的训练过程中，Hugging Face 团队利用了名为 “The Cauldron” 的50个高质量图像和文本数据集，以及名为 Docmatix 的文件扫描和详细说明配对的数据集。这两个数据集均由 Hugging Face 的 M4团队开发，专注于多模态 AI 技术的发展。值得注意的是，SmolVLM-256M 和 SmolVLM-500M 在各类基准测试中表现优于许多更大模型，如 Idefics80B，尤其是在 AI2D 测试中，它们在分析小学生科学图表的能力上表现突出。然而，小型模型虽然价格亲民且多才多艺，但它们在复杂推理任务上的表现可能不如大型模型。一项来自 Google DeepMind、微软研究院以及魁北克 Mila 研究所的研究显示，许多小型模型在这些复杂任务上的表现令人失望。研究人员推测，这可能是由于小型模型倾向于识别数据的表面特征，而在新情境中应用这些知识时则显得力不从心。Hugging Face 的 SmolVLM 系列模型不仅是体积小巧的 AI 工具，而且在处理各种任务时展现出了令人瞩目的能力。对于希望以低成本实现高效数据处理的开发者而言，这无疑是一个不错的选择。
