# Anthropic发布Citations功能，助力开发者获取AI生成答案的来源文献

**发布日期**: 2025年1月24号 9:28

![新闻图片](https://pic.chinaz.com/picmap/thumb/202307120853038799_0.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14969)

## 内容

为了加强其AI模型的透明性和可追溯性，Anthropic于周四宣布推出一项新功能——Citations。该功能旨在帮助开发者在通过Claude AI系列生成的答案中，提供来自源文档的精确引用，包括句子和段落。这一创新功能首次推出后，立即在Anthropic的API和Google的Vertex AI平台上提供支持。Citations功能:提高文档透明度与准确性根据Anthropic的介绍，Citations功能可以自动为开发者提供AI模型生成的答案来源，引用源文档中的确切句子和段落。这一功能尤其适用于文档摘要、问答系统以及客户支持应用程序，能够增强回答的可信度与透明度。通过引入源文献，开发者能够更清晰地了解AI模型的推理过程，减少“幻觉”现象（即AI生成的无依据或错误信息）。适用范围和定价尽管Citations功能的推出引发了广泛关注，但目前仅限于Anthropic的Claude3.5Sonnet和Claude3.5Haiku模型使用。此外，该功能并非免费的，Anthropic会根据源文档的长度和数量收取相应费用。例如，约100页的源文档，使用Claude3.5Sonnet时的费用大约为0.30美元，使用Claude3.5Haiku时则为0.08美元。这对于那些希望减少AI生成错误和不准确内容的开发者来说，可能是一个值得投资的选项。Citations:应对AI幻觉与错误的有效工具Citations的推出无疑增强了Anthropic在AI生成内容领域的竞争力，特别是在解决AI模型“幻觉”问题方面。AI的幻觉问题一直是开发者和用户面临的挑战之一，而Citations功能则为AI生成内容的可靠性提供了更多保障，确保开发者能够清楚地看到AI生成内容的来源。通过这种方式，Anthropic不仅提高了产品的透明度，还为开发者提供了更多工具，以确保生成的内容更加精准和可验证。总结随着AI技术的不断发展，透明性和可追溯性越来越成为用户和开发者关注的焦点。Anthropic推出的Citations功能，正是回应这一需求，为开发者提供了更高层次的控制和确保AI内容正确性的能力。未来，这一功能或将成为AI开发工具中的标准配置，推动整个行业向着更加可信赖的方向发展。
