# Pipeshift推出模块化推理引擎，实现AI推理GPU使用率降低75%

**发布日期**: 2025年1月24号 10:04

![新闻图片](https://upload.chinaz.com/2025/0124/6387330985204875144643747.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14977)

## 内容

近日，初创公司 Pipeshift 推出了一款全新的端到端平台，旨在帮助企业更高效地训练、部署和扩展开源生成式 AI 模型。该平台不仅可以在任何云环境或本地 GPU 上运行，还能够显著提升推理速度和降低成本。随着 AI 技术的迅猛发展，许多企业面临着如何在多种模型之间高效切换的挑战。传统上，团队需要构建一个复杂的 MLOps 系统，涉及计算资源的获取、模型训练、精调以及生产级部署等多个环节，这不仅需要花费大量的时间和工程资源，还可能导致基础设施的管理成本不断增加。Pipeshift 的联合创始人兼首席执行官阿尔科・查托帕迪亚（Arko Chattopadhyay）指出，开发一个灵活、可模块化的推理引擎往往需要数年的时间积累经验，而 Pipeshift 的解决方案则旨在通过其模块化推理引擎，简化这一过程。该平台采用了一种称为 MAGIC(GPU 推理集群模块化架构)的框架，允许团队根据具体的工作负载需求灵活组合不同的推理组件，从而在不需要繁琐工程的前提下，优化推理性能。例如，一家财富500强零售公司在使用 Pipeshift 平台后，将原本需要四个独立 GPU 实例来运行的四个模型，整合到一个单一的 GPU 实例上。通过这种方式，该公司不仅在推理速度上实现了五倍的提升，还将基础设施成本降低了60%。这一成果使得企业能够在快速发展的市场中保持竞争力。Pipeshift 目前已经与30家公司达成了年度授权协议，未来还计划推出帮助团队构建和扩展数据集的工具。这将进一步加速实验和数据准备过程，提高客户的工作效率。官方入口:https://pipeshift.com/划重点:🌟 Pipeshift 推出的模块化推理引擎可以显著降低 AI 推理的 GPU 使用率，降低成本达60%。🚀 通过 MAGIC 框架，企业可以快速组合推理组件，提升推理速度，减少工程负担。🤝 Pipeshift 已与多家公司达成合作，未来将推出更多工具，助力企业更高效地管理 AI 工作负载。
