# 谷歌发布全新视觉语言模型 PaliGemma 2 Mix 集成多种功能助力开发者

**发布日期**: 2025年2月20号 11:37

![新闻图片](https://upload.chinaz.com/2025/0220/6387564817678580417536477.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/15551)

## 内容

近日，谷歌宣布推出一款全新的视觉 - 语言模型（Vision-Language Model， VLM），名为 PaliGemma2Mix。这款模型融合了图像处理与自然语言处理的能力，能够同时理解视觉信息和文本输入，并根据需求生成相应的输出，标志着人工智能技术在多任务处理方面的进一步突破。PaliGemma2Mix 的功能非常强大，它集成了图像描述、光学字符识别（OCR）、图像问答、目标检测和图像分割等多种视觉 - 语言任务，适用于多种应用场景。开发者可以通过预训练检查点(checkpoints)直接使用这款模型，或根据自己的需求进行进一步微调。该模型是基于先前的 PaliGemma2进行优化而来，专门针对混合任务进行了调整，旨在让开发者轻松探索其强大的能力。PaliGemma2Mix 提供三种参数规模供开发者选择，包括3B（30亿参数）、10B(100亿参数)和28B(280亿参数)，并支持224px 和448px 两种分辨率，适应不同计算资源和任务需求。PaliGemma2Mix 的主要功能亮点包括:1. 图像描述:模型能够生成短篇和长篇的图像说明，例如识别一张牛站在海滩上的图片并提供详细描述。2. 光学字符识别（OCR）:该模型可以从图像中提取文字，识别标志、标签及文档内容，为信息提取提供便利。3. 图像问答与目标检测:用户可通过上传图片并提出问题，模型会分析图片并给出答案，此外，它还能准确识别图像中的特定对象，如动物、车辆等。值得一提的是，开发者可以在 Kaggle 和 Hugging Face 上下载这款模型的混合权重，便于进行进一步的实验与开发。如果你对这款模型感兴趣，可以通过 Hugging Face 的演示平台进行探索，了解其强大的能力与应用潜力。随着 PaliGemma2Mix 的推出，谷歌在视觉 - 语言模型领域的研究又向前迈进了一步，期待这项技术能够在实际应用中展现更大的价值。技术报告:https://arxiv.org/abs/2412.03555
