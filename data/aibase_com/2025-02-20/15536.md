# 微软团队推多模态AI模型Magma：整合视觉、语言和动作决策技能

**发布日期**: 2025年2月20号 9:30

![新闻图片](https://upload.chinaz.com/2025/0220/6387564058488626429264482.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/15536)

## 内容

近日，微软研究团队联合多所高校的研究人员，发布了一款名为 “Magma” 的多模态 AI 模型。这款模型的设计旨在处理和整合图像、文本和视频等多种数据类型，以便在数字和物理环境中执行复杂任务。随着科技的不断进步，多模态 AI 代理正在被广泛应用于机器人技术、虚拟助手和用户界面自动化等领域。以往的 AI 系统通常专注于视觉 - 语言理解或机器人操作，难以将这两种能力结合成一个统一的模型。许多现有模型虽然在特定领域内表现良好，但在不同应用场景中的泛化能力较差。例如，Pix2Act 和 WebGUM 模型在 UI 导航方面表现优异，而 OpenVLA 和 RT-2则更适合机器人操控，但它们往往需要分别进行训练，难以跨越数字和物理环境的界限。“Magma” 模型的推出，正是为了克服这些局限性。它通过引入一套强大的训练方法，整合多模态理解、动作定位和规划能力，旨在让 AI 代理在各种环境中无缝运行。Magma 的训练数据集包含了3900万样本，包括图像、视频和机器人动作轨迹。此外，该模型还采用了两项创新技术:“可标记集”（Set-of-Mark，SoM）和 “轨迹标记”(Trace-of-Mark，ToM)。前者使模型能够标记 UI 环境中的可操作视觉对象，后者则使其能够追踪物体随时间的移动，提升未来行动的规划能力。“Magma” 采用了先进的深度学习架构和大规模的预训练技术，以优化其在多个领域的表现。模型使用 ConvNeXt-XXL 视觉主干处理图像和视频，LLaMA-3-8B 语言模型负责处理文本输入。这种架构使 “Magma” 能够高效整合视觉、语言与动作执行。经过全面的训练，模型在多个任务上都取得了优异的成绩，显示出强大的多模态理解和空间推理能力。项目入口:https://microsoft.github.io/Magma/划重点:🌟 Magma 模型经过3900万多样本训练，具备强大的多模态学习能力。🤖 该模型成功整合视觉、语言和行动，克服了现有 AI 模型的局限性。📈 Magma 在多项基准测试中表现出色，显示出较强的泛化能力和优异的决策执行能力。
