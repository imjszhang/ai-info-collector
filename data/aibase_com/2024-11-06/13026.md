# 中国团队发布全球最大开源多模态数据集，2B参数模型性能创新高

**发布日期**: 2024年11月6号 9:53

![新闻图片](https://pic.chinaz.com/picmap/202304251756319059_4.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/13026)

## 内容

近日，来自多家中国科研机构的研究团队重磅发布了名为Infinity-MM的超大规模多模态数据集，并基于该数据集训练出了一个性能卓越的AI模型Aquila-VL-2B。这一突破为多模态AI发展注入了新动力。Infinity-MM数据集规模惊人，共包含四大类数据:1000万条图像描述、2440万条通用视觉指令数据、600万条精选高质量指令数据，以及300万条由GPT-4等AI模型生成的数据。研究团队采用开源AI模型RAM++进行图像分析和信息提取，并通过独特的六大类分类系统确保生成数据的质量和多样性。图源备注：图片由AI生成，图片授权服务商Midjourney在模型架构方面，Aquila-VL-2B基于LLaVA-OneVision构建，整合了Qwen-2.5语言模型和SigLIP图像处理技术。研究团队采用了四阶段渐进式训练方法:从基础的图文关联学习开始，逐步过渡到通用视觉任务、特定指令处理，最后融入合成数据，同时逐步提升图像分辨率上限。尽管仅有20亿参数规模，Aquila-VL-2B在各项基准测试中表现亮眼。在多模态理解能力测试MMStar中取得54.9%的最佳成绩，在数学能力测试MathVista中更是达到59%的高分，显著超越同类系统。在通用图像理解测试中，该模型在HallusionBench和MMBench分别获得43%和75.2%的优异成绩。研究发现，合成数据的引入对模型性能提升贡献显著。实验表明，若不使用这些额外数据，模型性能平均下降2.4%。从第三阶段开始，Aquila-VL-2B的性能就显著超越了InternVL2-2B和Qwen2VL-2B等参考模型，特别是在第四阶段，随着数据量增加，性能提升更为明显。值得一提的是，研究团队已将数据集和模型向研究社区开放，这将极大促进多模态AI技术的发展。该模型不仅在Nvidia A100GPU上完成训练，还支持中国自研芯片，展现了强大的硬件适应性。
