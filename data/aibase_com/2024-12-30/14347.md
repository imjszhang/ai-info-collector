# 豆包大模型发布2024年8个关键瞬间：从AI新星到全面突破

**发布日期**: 2024年12月30号 6:04

![新闻图片](https://pic.chinaz.com/picmap/thumb/202405160822226470_0.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14347)

## 内容

今日，豆包大模型官方发布豆包大模型的8个关键时刻!自2024年5月15日首次亮相以来，豆包大模型已破土而出，历经230天加速成长。从初步的学语，到懵懂的世界探索，再到为创作者绘制奇幻梦境，这一路的每一步都充满了挑战与成就。1.语音识别与情感表达的突破豆包大模型在7月实现了语音识别领域的一大突破:能听懂超过20种方言的混合对话，并且具备边听边思考的能力。不仅如此，它还学会了在对话中表达情感，能在交互中自如地插话，甚至保留吞音和口音等人类语言习惯。这背后的核心技术是豆包语音识别模型Seed-ASR与语音生成基座模型Seed-TTS，这些模型融合了更广泛的数据和推理链，使其具有极强的泛化能力。2.AI乐队的诞生9月，豆包大模型创造性地实现了“AI乐队”概念。从词曲创作到演奏生成，再到人声演唱，豆包大模型掌握了超过10项音乐创作技能，能够为音乐创作带来意想不到的灵感。背后的技术是Seed-Music框架，它结合了语言模型与扩散模型的优势，实现了音乐生成的通用框架，并且具备极高的编辑可控性。3.精准视频生成与镜头控制同月，豆包大模型进一步打破创作边界，能够遵循复杂的提示词，生成多主体的高清视频，并精准控制镜头视角。借助PixelDance与Seaweed两个视频生成模型，豆包大模型能够实现高质量的视频与音效同步生成，为创作者提供更加真实且梦幻的视觉体验。4.图像编辑与创作能力的升级11月，豆包大模型掌握了“一句话P图”和“一键海报生成”的能力。用户只需简单的文字指令，就能进行精准的图像编辑和文字生成。通过不断迭代的文生图模型SeedEdit，豆包能够精准呈现复杂场景，提供自然语言驱动的图像编辑。5.编程能力飞跃进入12月，豆包大模型的编程能力得到了大幅提升，成为了AI程序员与数据分析师。通过豆包MarsCode，用户可以轻松实现代码编写、数据处理与可视化分析。豆包的代码大模型Doubao-coder深度支持16种编程语言，并能满足前后端开发、机器学习等全栈编程需求。6.极限文本理解与处理能力豆包大模型还突破了上下文窗口的极限，提升至300万字，能够处理更大规模的文本，并在每百万tokens的处理延迟仅需15秒。通过STRING等关联数据算法，豆包大模型能够快速获取海量外部知识，并提供更精确的理解能力。7.视觉感知与深度思考的突破12月中旬，豆包大模型实现了视觉感知能力，并能够融合多感官进行深度思考。它不仅能准确理解图像，还能进行复杂运算，例如拍下一道微积分数学题，展现了其卓越的跨模态学习和推理能力。8.全面升级的通用模型Doubao-pro在12月中旬，豆包通用模型Doubao-pro全面升级，能力全方位对齐GPT-4，并学会在回答过程中进行“反思”。这一升级提升了Doubao-pro的理解精度与生成质量，使其成为一个高效的“六边形战士”，在各项能力上均衡表现，成为AI领域的又一标杆。这一年，豆包大模型团队在AI基础研究上取得了显著进展。团队发布了57篇论文，并在ICLR、CVPR、NeurIPS等顶会亮相。此外，豆包大模型团队与多所顶级高校深入合作，成立了联合实验室，推动AI技术的发展。豆包大模型不仅在技术上取得突破，也广泛应用于多个行业。通过火山引擎，豆包大模型服务了30多个行业，日均tokens调用量超4万亿，较5月发布时增长了33倍。官方地址:https://mp.weixin.qq.com/s/KVfu86njzyK2iK4j6VJONw
