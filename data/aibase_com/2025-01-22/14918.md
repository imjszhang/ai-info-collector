# 研究发现，AI 模型为对青少年充满负面印象

**发布日期**: 2025年1月22号 10:14

![新闻图片](https://pic.chinaz.com/picmap/202304211121374347_0.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14918)

## 内容

人工智能技术不断发展，越来越多的人开始关注 AI 系统对青少年的描绘。华盛顿大学的博士生罗伯特・沃尔夫在一次实验中让 AI 系统完成句子 “这个青少年在学校_____”。他原本期待的答案是 “学习” 或 “玩耍”，却意外得到 “死去” 这一惊人回答。这一发现促使沃尔夫和他的团队深入研究 AI 如何刻画青少年。图源备注:图片由AI生成，图片授权服务商Midjourney研究团队分析了两种常见的英文开源 AI 系统和一种尼泊尔语系统，试图比较不同文化背景下 AI 模型的表现。结果发现，在英文系统中，大约30% 的回答涉及暴力、药物滥用和心理疾病等社会问题，而尼泊尔系统则仅有约10% 的回答为负面。这一结果引发了团队的担忧，他们在与美国和尼泊尔的青少年进行的研讨会中发现，两个群体均认为基于媒体数据训练的 AI 系统无法准确代表他们的文化。研究还涉及到 OpenAI 的 GPT-2和 Meta 的 LLaMA-2等模型，研究人员通过给系统提供句子提示，让其完成后续内容。结果显示，AI 系统的输出与青少年自身的生活经历存在很大差距。美国青少年希望 AI 能够反映更多样化的身份，而尼泊尔青少年则希望 AI 能更积极地表现他们的生活。尽管研究所用的模型并非最新版本，但这项研究揭示了 AI 系统在青少年描绘方面存在的根本性偏见。沃尔夫表示，AI 模型的训练数据往往倾向于报道负面新闻，而忽视了青少年日常生活的平常一面。他强调，需要进行根本性的改变，以确保 AI 系统能够从更广泛的视角反映青少年的真实生活。研究团队呼吁，AI 模型的训练应更加关注社区的声音，让青少年的观点和经历成为训练的初始来源，而不是仅仅依赖那些吸引眼球的负面报道。划重点:🌍 研究发现，AI 系统对青少年的描绘往往偏向负面，其中英文模型的负面关联率高达30%。🤖 通过与美国和尼泊尔青少年进行的研讨会，发现他们认为 AI 无法准确代表自己的文化和生活。📊 研究团队强调，需要重新审视 AI 模型的训练方法，以更好地反映青少年的真实经历。
