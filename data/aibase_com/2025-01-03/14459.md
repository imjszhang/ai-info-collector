# 字节跳动发布Infinity：自回归文生图新突破，性能超越扩散模型

**发布日期**: 2025年1月3号 16:00

![新闻图片](https://upload.chinaz.com/2025/0103/6387151672766816955755047.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14459)

## 内容

在人工智能领域，字节跳动商业化技术团队的最新成果Infinity模型，以其卓越的性能和创新的技术，成为自回归文生图领域的新王者。这款新开源的模型不仅在图像生成质量上超越了Stable Diffusion3，还在推理速度上展现了显著优势。Infinity模型的核心创新在于采用了Bitwise Token的自回归框架，这一框架通过预测下一级分辨率的+1或-1构成的细粒度“Bitwise Token”，显著提升了模型对高频信号的捕捉能力，从而生成细节更加丰富的图像。此外，Infinity模型将词表扩展到无穷大，极大地增强了Image tokenizer的表示空间，提高了自回归文生图的性能上限。在性能对比中，Infinity模型在自回归方法中表现突出，远超HART、LlamaGen、Emu3等方法，并在人类评测中以接近90%的胜率击败了HART模型。同时，Infinity也以75%、80%、65%的胜率击败了SOTA的扩散模型如PixArt-Sigma、SD-XL、SD3-Meidum等，证明了其在同尺寸模型中的优势。Infinity模型的另一大特点是其良好的scaling特性。随着模型大小的增加和训练资源的投入，验证集损失稳步下降，验证集准确率稳定提升。此外，Infinity还提出了比特自我矫正技术，增强了模型的自我矫正能力，缓解了自回归推理时的累计误差问题。在推理速度上，Infinity继承了VAR的速度优势，2B模型生成1024x1024的图像仅需0.8秒，比同尺寸的SD3-Medium快3倍，比12B的Flux Dev快14倍。8B模型比同尺寸的SD3.5快7倍，20B模型生成1024x1024的图像用时3秒，比12B的Flux Dev快近4倍。目前，Infinity模型的训练和推理代码、demo、模型权重已在GitHub仓库上线，同时提供了网站体验，方便用户试用和评估模型效果。项目页:https://foundationvision.github.io/infinity.project/
