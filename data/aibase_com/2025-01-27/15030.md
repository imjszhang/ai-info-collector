# 阿里云 Qwen2.5-1M 开源发布:100万上下文长度模型登场

**发布日期**: 2025年1月27号 11:08

![新闻图片](https://pic.chinaz.com/picmap/202310311416147098_0.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/15030)

## 内容

继 DeepSeek R1之后，阿里云通义千问团队刚刚宣布推出其最新的开源模型Qwen2.5-1M，再次引发业界关注。此次发布的 Qwen2.5-1M 系列包含两个开源模型:Qwen2.5-7B-Instruct-1M 和 Qwen2.5-14B-Instruct-1M。这是通义千问首次推出能够原生支持百万Token上下文长度的模型，并在推理速度上实现了显著提升。Qwen2.5-1M 的核心亮点在于其原生支持百万 Token 的超长上下文处理能力。这使得模型能够轻松应对书籍、长篇报告、法律文件等超长文档，无需进行繁琐的分割处理。同时，该模型还支持更长时间、更深入的对话，能够记住更长的对话历史，实现更连贯、更自然的交互体验。此外，Qwen2.5-1M 在理解复杂任务，如代码理解、复杂推理、多轮对话等方面也展现出更强大的能力。除了令人震撼的百万Token上下文长度，Qwen2.5-1M 还带来了另一项重大突破:闪电般快速的推理框架!通义千问团队完全开源了基于 vLLM 的推理框架，并集成了稀疏注意力机制。这一创新性的框架使得 Qwen2.5-1M 在处理百万 Token 输入时，速度提升了3倍到7倍!这意味着用户可以更加高效地使用超长上下文模型，极大地提升了实际应用场景的效率和体验。
