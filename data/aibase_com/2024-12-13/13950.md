# ​科技公司声称 AI 能识别情感，但科学证据却不支持这一说法

**发布日期**: 2024年12月13号 8:46

![新闻图片](https://pic.chinaz.com/picmap/202304251756303409_0.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/13950)

## 内容

近年来，情感识别技术在科技行业中逐渐崭露头角。许多技术公司推出了 AI 驱动的情感识别软件，声称能够通过生物数据来判断一个人的情感状态，包括快乐、悲伤、愤怒和沮丧。然而，越来越多的科学研究表明，这些技术的可靠性并不如宣传的那样。图源备注：图片由AI生成，图片授权服务商Midjourney根据最新的研究，情感识别技术面临着严重的科学有效性问题。许多公司声称这些系统是客观的，根植于科学的方法，但实际上，它们往往依赖于一些过时的理论。这些理论认为情感是可以被量化并且在全球范围内都有相同的表现形式，但实际上，情感的表达受到文化、环境和个体差异的深刻影响。例如，人的皮肤湿度可能在愤怒时上升、下降或保持不变，这使得单一的生物指标无法准确判断情感。与此同时，这些情感识别技术也带来了法律和社会风险，尤其是在职场中。根据欧盟的新规，除非出于医疗或安全原因，否则禁止在工作场所使用情感推断的 AI 系统。而在澳大利亚，这方面的监管尚未跟上步伐。虽然一些公司曾尝试在招聘中使用面部情感分析，但这些技术的有效性和伦理性引发了广泛的质疑。此外，情感识别技术还存在潜在的偏见问题。这些系统在识别情感时，可能对不同种族、性别和残疾人群表现出歧视。例如，某些研究表明，情感识别系统在别黑人面孔时往往更倾向于认为他们生气，尽管双方表现出的微笑程度相同。尽管技术公司承认情感识别存在偏见的问题，但他们强调偏见主要源于用于训练这些系统的数据集。针对这一问题，inTruth Technologies 表示将致力于使用多样化和包容性的数据集来减少偏见。公众对情感识别技术的看法并不乐观。最近的一项调查显示，仅有12.9% 的澳大利亚成年人支持在职场中使用基于面部的情感识别技术，许多人认为这是一种侵犯隐私的行为。划重点:🌐 全球市场正在迅速增长，但情感识别技术的科学依据受到质疑。⚖️ 欧盟已禁止在职场使用情感推断的 AI 系统，澳大利亚则亟需制定相关法规。🤖 大众普遍对情感识别技术持负面态度，认为其侵犯隐私且存在偏见。
