# ​新型AI图像生成框架OminiControl：可将素材主体融入生成图片中

**发布日期**: 2024年11月26号 14:28

![新闻图片](https://upload.chinaz.com/2024/1126/6386822753409222179213403.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/13485)

## 内容

在当今数字时代，图像生成技术正以惊人的速度发展。最近，来自新加坡国立大学的研究团队提出了一种全新的框架 ——OminiControl，旨在提升图像生成的灵活性和效率。该框架通过结合图像条件，充分利用已经训练好的扩散变换器（Diffusion Transformer，简称 DiT）模型，带来了前所未有的控制能力。简单的说，只要提供素材图，利用OminiControl就能将素材图中的主题融入到生成的图片中。比如小编上传了左边的素材图，输入提示词“芯片人放置在一个医生办公室的桌子旁边，桌子上放着听诊器”，生成效果比较一般，如下:OminiControl 的核心在于其 “参数重用机制”。这种机制使得 DiT 模型能够以更少的额外参数有效地处理图像条件。这意味着，相较于现有的方法，OminiControl 仅需增加0.1% 到0.1% 的参数就能实现强大的功能。此外，它能够统一处理多种图像条件任务，比如基于主题的生成和空间对齐条件的应用，比如边缘、深度图等。这种灵活性特别适用于主题驱动的生成任务。研究团队还特别强调，OminiControl 是通过训练生成的图像来实现这些能力的，这对于主题驱动的生成尤为重要。经过广泛的评估，OminiControl 在主题驱动生成和空间对齐条件生成的任务中，都显著超过了现有的 UNet 模型和 DiT 适应模型。这一研究成果为创作领域带来了新的可能性。为了支持更广泛的研究，团队还发布了一个名为 Subjects200K 的训练数据集，包含了超过20万张身份一致的图像，并提供了高效的数据合成管道。这个数据集将为研究人员提供宝的资源，帮助他们进一步探索主题一致生成任务。Omini 的推出不仅提升了图像生成的效率与效果，也为艺术创作提供了更多可能性。随着技术的不断进步，未来的图像生成将更加智能化和个性化。在线体验:https://huggingface.co/spaces/Yuanshi/OminiControlgithub:https://github.com/Yuanshi9815/OminiControl论文:https://arxiv.org/html/2411.15098v2划重点:🌟 OminiControl 通过参数重用机制，让图像生成的控制能力更强大，效率更高。🎨 该框架能同时处理多种图像条件任务，如边缘、深度图等，适应不同创作需求。📸 团队发布了超过20万张图像的数据集 Subjects200K，助力进一步的研究与探索。
