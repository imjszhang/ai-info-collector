# Claude 强势进驻美军情报，背后谁在掌控？

**发布日期**: 2024年11月8号 9:19

![新闻图片](https://pic.chinaz.com/picmap/thumb/202307211343369900_5.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/13077)

## 内容

近日，Palantir 宣布与 Anthropic 及亚马逊网络服务（AWS）建立合作，旨在构建一个适合美国政府国防和情报使用的 Claude 云平台。根据三家公司在公告中透露的消息，这一合作将把 Claude3和3.5集成到 Palantir 的人工智能平台中，而该平台将托管在 AWS 上。值得一提的是，Palantir 和 AWS 已经获得了美国国防部颁发的影响级别6（IL6）认证，这使得它们可以处理和存储最高机密级别的数据。Anthropic 的一位发言人表示，Claude首次在10月初向国防和情报界开放。美国政府将利用 Claude 来减少数据处理时间、识别模式和趋势、简化文件审查，并帮助官员在时间紧迫的情况下做出更明智的决策，同时保持其决策权。Palantir 的首席技术官 Shyam Sankar 表示:“Palantir 很自豪成为第一个将 Claude 模型带入保密环境的行业合作伙伴。”与 Meta 的情况不同，后者在最近宣布将 Llama 开放给美国政府用于国防和国家安全应用时，设定了相关的使用政策。Anthropic 则没有必要对其可接受使用政策（AUP）进行例外处理，这使得 Claude 在美国国防部、中央情报局或其他使用它的国防和情报机构中可以应用于潜在危险的领域。尽管 Anthropic 已经在其 AUP 中明确了一些高风险使用案例，但却没有限制其在国防和情报领域的应用，只有在法律、医疗、保险、金融、就业、住房、学术和媒体等领域提及使用 Claude 是 “关乎公众福利和社会公平的领域”。当被询问 AUP 与政府应用的关系时，Anthropic 仅提及一篇关于扩展政府对 Claude 访问权限的博客文章。在该博客中，Anthropic 提到已经建立了对政府用户的可接受使用政策例外的授予机制，并强调这些例外是 “经过精心校准的，以便让经过严格选择的政府机构获得有益的使用”。不过，这些例外具体是什么尚不清楚。Anthropic 还表示，现有的例外结构允许 Claude 用于法律授权的外国情报分析，并提前提供潜在军事活动的预警，从而为外交开辟窗口以预防或阻止冲突。然而，涉及虚假信息、武器设计和使用、审查及恶意网络操作等其他限制依然存在。划重点:💻  Palantir 与 Anthropic 和 AWS 合作，推出适合美国国防情报的 Claude 云平台。🛡️  Claude 被用于数据处理、模式识别和决策支持，无需对其可接受使用政策进行例外处理。📜  Anthropic 的可接受使用政策允许在国防领域的某些应用，但对高风险领域没有明确限制。
