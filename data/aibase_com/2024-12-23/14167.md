# ​新一代语言模型ModernBERT发布，RAG等任务处理速度快四倍、成本低

**发布日期**: 2024年12月23号 1:53

![新闻图片](https://upload.chinaz.com/2024/1223/6387054434779027946639690.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/14167)

## 内容

最近，Answer.AI 和 LightOn 联合发布了开源语言模型 ModernBERT，这是对谷歌 BERT 的重大升级。根据开发者的介绍，ModernBERT 在处理速度、效率和质量上都有了显著提升。该模型可以比其前身快四倍，同时使用更少的内存。ModernBERT 的设计允许它处理长达8192个标记的文本，这比现有编码模型的典型512标记限制提高了16倍。此外，ModernBERT 还是首个经过广泛训练的编程代码编码模型，它在 StackOverflow 问答数据集上的得分超过80，创造了编码模型的新纪录。在通用语言理解评估（GLUE）中，ModernBERT-Large 的处理速度与准确性达到了最佳平衡，每个标记的处理时间约为20毫秒，得分为90。开发团队形象地将 ModernBERT 比作一辆经过调校的本田思域，强调其在日常应用中可靠而高效。与现有大型语言模型如 GPT-4相比，ModernBERT 在大规模文本处理上大幅降低了成本。GPT-4每次查询的费用为数美分，而 ModernBERT 则可以在本地运行，更快且更便宜。例如，FineWeb Edu 项目在过滤150亿个标记时，使用 BERT 模型的成本为6万美元，而即便使用谷歌的 Gemini Flash 解码器，成本也超过了100万美元。开发团队表示，ModernBERT 非常适合多种实际应用，包括检索增强生成（RAG）系统、代码搜索和内容审查。不同于需要专门硬件的 GPT-4，ModernBERT 可以在普通消费级游戏 GPU 上有效运行。目前，ModernBERT 提供两个版本:基础模型包含1.39亿个参数，大型版本包含3.95亿个参数。两个版本现已在 Hugging Face 上发布，并且用户可以直接用它们替换现有的 BERT 模型。开发团队计划在明年推出更大的版本，但没有多模态能力的计划。为了促进新应用的开发，他们还推出了一项比赛，将向五个最佳演示者奖励100美元和六个月的 Hugging Face 专业订阅。自2018年谷歌推出 BERT 以来，该模型一直是最受欢迎的语言模型之一，在 HuggingFace 上每月下载量超过6800万次。项目入口:https://huggingface.co/blog/modernbert划重点:🌟 ModernBERT 比 BERT 处理速度快四倍，能够处理长达8192个标记的文本。💰 相较于 GPT-4，ModernBERT 在大规模文本处理上的成本大幅降低，运行更高效。📊 该模型特别擅长处理编程代码，在 StackOverflow 问答数据集上得分超80，创造新纪录。
