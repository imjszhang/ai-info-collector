# Meta AI推出MILS系统 教导 LLMs无需专门培训即可处理多媒体数据

**发布日期**: 2025年2月10号 11:04

![新闻图片](https://upload.chinaz.com/2025/0210/6387478219001165477903428.png)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/15200)

## 内容

Meta AI的研究人员与学术伙伴共同开发了一种创新系统——MILS（多模态迭代LLM求解器），该系统能在无需经过专门训练的情况下，教大型语言模型处理图像、视频和音频。MILS依赖于语言模型的自然问题解决能力，而非大量的数据训练，展现了其独特的优势。MILS的工作原理是通过将两个AI模型配对来进行任务解决:一个是“生成器”，负责提出任务解决方案，另一个是“评分器”，用来评估生成方案的效果。评分器提供的反馈可以帮助生成器不断优化答案，直到达到令人满意的结果。举例来说，在图像描述任务中，MILS能够逐步细化图像描述，从而准确地描述不同层次的图像细节。在图像描述方面，MILS表现尤为出色。通过将Llama-3.1-8B模型作为生成器，CLIP模型作为评分器，MILS能够创建出与当前领先方法相当甚至更为详细的图像描述，尽管CLIP并未专门针对图像描述任务进行训练。此外，MILS还通过微调文本提示增强了文本到图像的生成能力，并且能将AI生成的提示与图像处理工具相结合，处理如风格转换等图像编辑任务。图像描述的准确性随着生成器和评分器之间的步骤数而增加。| 图片:Ashutosh 等人MILS的功能不仅限于图像，它也扩展到了视频和音频领域。在使用MSR-VTT视频数据集进行测试时，MILS在视频内容描述方面的表现优于现有模型。由于MILS在运行过程中不修改模型参数，它可以将不同类型的数据转换为可读文本，支持将来自图像、音频等多个来源的信息合并并转化为所需格式，从而为多模态信息融合应用开辟了新的可能。测试表明，使用更大的生成器和评分模型可以产生更准确的结果，增加潜在解决方案数量能显著提高性能。研究人员还发现，扩展到更大的语言模型不仅提升了结果的质量，还使得性能表现得到了明显改进。风景从简单的基本描述演变为具有更精确细节和更多自然元素的复杂景观表述。| 图片:Ashutosh 等人MILS所采取的这一创新策略，符合当前人工智能领域朝着更智能推理能力发展的趋势。Meta团队还表示，MILS在未来可能在3D数据处理等领域展现出巨大潜力，进一步推动多模态AI的发展。随着OpenAI的GPT-4和其他开源替代方案的快速发展，如Meta的Llama3.2、Mistral的Pixtral以及DeepSeek的Janus Pro等，这些新兴的多模态AI系统正在加速其对日常生活的应用，并为人工智能的未来发展奠定了重要基础。
