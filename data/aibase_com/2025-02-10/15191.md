# ​Meta AI 推脑机接口模型Brain2Qwerty，可通过脑电波解码打字内容

**发布日期**: 2025年2月10号 9:40

![新闻图片](https://pic.chinaz.com/picmap/202304171156367067_3.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/15191)

## 内容

在脑 - 机接口（BCI）技术日益发展的今天，Meta AI最新推出的 Brain2Qwerty 模型为这一领域带来了新的希望。BCI 旨在为有言语或运动障碍的人群提供沟通手段，但传统的方法通常需要侵入性手术，比如植入电极，这不仅存在医疗风险，还需要长期维护。因此，研究者们开始探索非侵入性的替代方案，尤其是基于脑电图(EEG)的方法。然而，EEG 技术面临着信号分辨率低的问题，影响了其准确性。图源备注:图片由AI生成，图片授权服务商MidjourneyBrain2Qwerty 的推出正是为了解决这一难题。这款深度学习模型可以从通过 EEG 或脑磁共振成像（MEG）捕捉到的脑活动中解码出参与者输入的句子。在研究中，参与者在 QWERTY 键盘上输入短暂记忆的句子，同时其脑活动被实时记录。与以往需要集中注意力在外部刺激或想象运动不同，Brain2Qwerty 利用了自然的打字运动，提供了一种更直观的脑电波解读方法。Brain2Qwerty 的架构分为三个主要模块。首先是卷积模块，负责提取 EEG 或 MEG 信号中的时间和空间特征。接着是变换器模块，它处理输入的序列，优化理解和表达。最后是语言模型模块，它是一个预训练的字符级语言模型，用于修正和提升解码结果的准确性。在评估 Brain2Qwerty 的性能时，研究者采用了字符错误率（CER）作为衡量标准。结果显示，基于 EEG 的解码 CER 为67%，相对较高;而使用 MEG 的解码效果则显著改善，CER 降低至32%。在实验中，表现最好的参与者达到了19% 的 CER，显示了该模型在理想条件下的潜力。尽管 Brain2Qwerty 在非侵入性 BCI 领域展现了积极的前景，但仍面临几项挑战。首先，当前模型需要处理完整句子，而不是逐个按键进行实时解码。其次，虽然 MEG 的性能优于 EEG，但其设备尚不便携且普及性不足。最后，本研究主要在健康参与者中进行，未来需要深入探讨其对运动或言语障碍者的适用性。论文:https://ai.meta.com/research/publications/brain-to-text-decoding-a-non-invasive-approach-via-typing/划重点:🧠 Meta AI 推出的 Brain2Qwerty 模型能通过 EEG 和 MEG 解码打字内容，为 BCI 技术带来新希望。📊 研究结果显示，使用 MEG 解码的字符错误率显著低于 EEG，最优参与者达19% 的 CER。🔍 未来的挑战包括实时解码、MEG 设备的可及性以及在有障碍人士中的应用效果。
