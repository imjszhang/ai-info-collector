# 腾讯云TI平台上架DeepSeek系列模型 支持免费体验和一键部署

**发布日期**: 2025年2月4号 14:34

![新闻图片](https://pic.chinaz.com/picmap/thumb/201811151633427149_4.jpg)

**新闻链接**: [点击查看原文](https://www.aibase.com/zh/news/15052)

## 内容

近日，腾讯云TI平台宣布正式上架备受瞩目的DeepSeek系列模型，包括参数量达到671B的“满血版”V3和R1原版模型，以及基于DeepSeek-R1蒸馏得到的系列模型，参数规模从70B到1.5B不等。这一举措为开发者提供了强大的AI工具支持，进一步推动了大模型技术的普及和应用。DeepSeek系列模型以其卓越的性能在全球范围内获得了广泛关注。其中，DeepSeek-R1在发布时即开源，并在后训练阶段大规模使用了强化学习技术，即使在仅有极少标注数据的情况下，也能极大提升模型推理能力。在数学、代码、自然语言推理等任务上，DeepSeek-R1的性能与OpenAI的GPT-4正式版不相上下。此外，DeepSeek-R1遵循MIT License，允许用户通过蒸馏技术训练其他模型，其蒸馏模型DeepSeek-R1-Distill在参数规模更小、推理成本更低的情况下，依然在基准测试中表现出色。腾讯云TI平台不仅全面支持DeepSeek系列模型的一键部署，还限时开放了R1模型的免费在线体验，为开发者提供了零门槛的开箱体验。用户可以在“TI平台-大模型广场”中点击DeepSeek系列模型卡片，了解模型信息，并进行在线体验和一键部署。此外，TI平台还提供了模型服务管理、监控运营、资源伸缩等企业级能力，帮助企业和开发者将DeepSeek模型高效、稳定地接入实际业务中。为了满足不同用户的需求，TI平台提供了多种计费模式，包括按量计费和包年包月。对于需要短时体验的用户，可以直接从TI平台购买算力并选用按量计费模式;而对于已购买CVM机器或需要长时间体验的用户，则推荐使用自有的CVM机器作为推理算力。在算力配置方面，“满血版”DeepSeek-R1推荐使用腾讯云上的2台8卡HCCPNV6机型进行服务部署，以获得稳定业务体验;而蒸馏后的DeepSeek-R1-Distill-Qwen-1.5B模型则可以单张中端GPU卡进行部署。开发者可以根据业务复杂度选择合适的模型进行测试，并通过调用API的方式将其接入AI应用。腾讯云TI平台的这一新动作，不仅为开发者提供了强大的AI工具支持，也为大模型技术的普及和应用提供了有力的推动。通过免费体验和一键部署功能，TI平台降低了开发者使用大模型的门槛，使其能够更快速地将AI技术应用于实际业务中，进一步提升了AI技术的实用性和可及性。
